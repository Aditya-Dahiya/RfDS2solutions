---
title: "Chapter 13"
author: "Aditya Dahiya"
subtitle: "Logical Vectors"
date: 2023-09-03
execute: 
  echo: true
  warning: false
  error: false
  cache: true
filters:
  - social-share
share:
  permalink: "https://aditya-dahiya.github.io/RfDS2solutions/Chapter13.html"
  description: "Solutions: R for Data Science (2e)"
  twitter: true
  facebook: true
  linkedin: true
  email: true
editor_options: 
  chunk_output_type: console
fig-width: 10
bibliography: references.bib
---

Some important take-away points

-   Use `near()` instead of `==` when comparing numbers to ignore very small differences due to the way computers store numbers.

-   Since, `NA != NA` , we have to use another function to find `NAs` in the data, i.e., `is.na()` . For example, `filter(flights,dep_time == NA)` will not yield any row. Instead, we should use `filter(flights, is.na(dep_time))` .

-   To shown missing values first, we will have to use `arrange(<DF>, desc(is.na(<Var_Name>)), <Var_Name>)`

```{r}
#| label: setup

library(tidyverse)
library(nycflights13)
data("flights")
library(gt)
```

# **13.2.4 Exercises**

## Question 1

**How does [`dplyr::near()`](https://dplyr.tidyverse.org/reference/near.html) work? Type `near` to see the source code. Is `sqrt(2)^2` near 2?**

`dplyr::near()` is used for testing whether two numeric values are close to each other within a certain **tolerance**. This is useful when working with floating-point numbers, where exact equality can be problematic due to precision limitations. It takes three arguments:

-   `x`: The first numeric value to compare.

-   `y`: The second numeric value to compare.

-   `tol`: Tolerance level, which is a small positive numeric value that defines how close `x` and `y` need to be to be considered "near." By default, it uses `.Machine$double.eps^0.5`, which is a good default for most cases.

Note 1: The variable `.Machine` contains data concerning the numerical attributes of the computer system where `R` is currently operating. This information encompasses details like the maximum values for double, and integer types, as well as the machine's precision.

Note 2: The `double.eps` value represents the smallest positive floating-point number `x` for which the equation `1 + x != 1` holds true. Its calculation involves the base of the double data type and the number of significant digits (`ulp.digits`). Specifically, if the base is 2 or the rounding method is 0, it equals `double.base ^ ulp.digits`. In other cases, it is `(double.base ^ double.ulp.digits) / 2`. Typically, this value is approximately `2.220446e-16`.

```{r}
#| collapse: true
#| label: q1-ex2

near
.Machine$double.eps
.Machine$double.eps^0.5
```

Thus, `dplyr::near()` works by checking whether the absolute value of the difference between `x` and `y` is less that the square-root of `.Machine$double.eps` or not.

As shown in the code below, yes, `sqrt(2)^2` is near 2.

```{r}
#| label: q1a-ex2
#| collapse: true
near(sqrt(2)^2, 2)
```

## Question 2

**Use [`mutate()`](https://dplyr.tidyverse.org/reference/mutate.html), [`is.na()`](https://rdrr.io/r/base/NA.html), and [`count()`](https://dplyr.tidyverse.org/reference/count.html) together to describe how the missing values in `dep_time`, `sched_dep_time` and `dep_delay` are connected.**

First, let us try to compute the number of rows where, as it should be, `sched_dep_time - dep_time == dep_delay`. As we see below, the results is `NA` since `NAs` are contagious in addition, the result returns `NA` .

```{r}
flights |>
  select(dep_time, sched_dep_time, dep_delay) |>
  mutate(check1 = sched_dep_time - dep_time == dep_delay) |>
  summarise(
    n = n(),
    equal = sum(check1)
  )
```

Now, let us rework the maths with using `is.na()` to remove missing values of departure time, i.e. cancelled flights. We can use `filter(!is.na(dep_time))` . The results indicate that 69.% of flights, the departure delay is equal to difference between departure time and scheduled departure time.

```{r}
flights |>
  select(dep_time, sched_dep_time, dep_delay) |>
  filter(!is.na(dep_time)) |>
  mutate(check1 = dep_time - sched_dep_time == dep_delay) |>
  summarise(
    total = n(),
    equal = sum(check1)
  ) |>
  mutate(perc_equal = (equal*100)/total)
```

Now, onto checking the relation between missing values. We observe that none of the Scheduled Departure Time values are missing. There are 8,255 missing Departure Time values, which indicate a cancelled flight. There are also 8,255 missing Departure Delay values, and we show below that these are the exact same flights for which the departure time is missing. Thus, the missing values in `dep_delay` and `dep_time` are connected and exaclty occurring for same rows.

```{r}
# Number of row with missing Scheduled Departure Time
flights |>
  filter(is.na(sched_dep_time)) |>
  count() |>
  as.numeric()

# The number of rows with missing Departure Time
flights |>
  filter(is.na(dep_time)) |>
  count() |>
  as.numeric()

# The number of rows with missing Departure Delay
flights |>
  filter(is.na(dep_delay)) |>
  count() |>
  as.numeric()

# Checking whether the exact same rows have missing values
# for Departure Time and Departure Delay
sum(which(is.na(flights$dep_time)) != which(is.na(flights$dep_delay)))

```

# **13.3.4 Exercises**

## Question 1

**Find all flights where `arr_delay` is missing but `dep_delay` is not. Find all flights where neither `arr_time` nor `sched_arr_time` are missing, but `arr_delay` is.**

The following code displays all flights where `arr_delay` is missing but `dep_delay` is not in @fig-q1-ex3. There are 1,175 such flights.

```{r}
#| label: fig-q1-ex3
#| fig-cap: "Table of all flights where arr_delay is missing but dep_delay is not"


flights |>
  filter(is.na(arr_delay) & !is.na(dep_delay)) |>
  select(flight, arr_delay, dep_delay) |>
  gt() |>
  cols_label(flight = "Flight Number",
             arr_delay = "Arrival Delay (in min)",
             dep_delay = "Departure Delay (in min)") |>
  opt_interactive(pagination_type = "jump")
```

The following code displays all flights where neither `arr_time` nor `sched_arr_time` are missing, but `arr_delay` is missing reflected in @fig-q1a-ex3. There are 717 such flights.

```{r}
#| label: fig-q1a-ex3
#| fig-cap: "Table of all flights where arr_delay is missing but dep_delay is not"
flights |>
  filter(!is.na(arr_time) & !is.na(sched_arr_time) & is.na(arr_delay)) |>
  select(flight, arr_time, sched_arr_time, arr_delay) |>
  gt() |>
  cols_label(flight = "Flight Number",
             arr_delay = "Arrival Delay (in min)",
             arr_time = "Arrival Time (hrs)",
             sched_arr_time = "Scheduled Arrival Time (hrs)") |>
  opt_interactive(pagination_type = "jump")
```

## Question 2

**How many flights have a missing `dep_time`? What other variables are missing in these rows? What might these rows represent?**

The following code shows us that 8,255 flights have a missing `dep_time` . Further, @fig-q2-ex3 shows us that these flights have missing `dep_delay` , `arr_time` , `arr_delay` and `air_time`. Further, around 30% of these have missing `tailnum`.

Thus, these rows most likely represent cancelled flights.

```{r}
#| label: fig-q2-ex3
#| fig-cap: "Visualization of missing values in flights with missing dep_time"

flights |>
  filter(is.na(dep_time)) |>
  count() |> as.numeric()

flights |>
  filter(is.na(dep_time)) |>
  naniar::vis_miss() +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.x.top = element_text(angle = 90))
```

## Question 3

**Assuming that a missing `dep_time` implies that a flight is cancelled, look at the number of cancelled flights per day. Is there a pattern? Is there a connection between the proportion of cancelled flights and the average delay of non-cancelled flights?**

As shown in @fig-q3a-ex3 below, when seen over the entire course of year, no specific pattern emerges. However, certain months show more number of spikes - there is one day with large number of cancellations (over 400) in February. When seen month-wise, as in @fig-q3b-ex3 , it becomes apparent that most flight cancellations occur in December - March; or in June-July.

```{r}
#| label: fig-q3a-ex3
#| code-fold: true
#| fig-width: 10


flights |>
  filter(is.na(dep_time)) |>
  mutate(date = make_date(year = year,
                          month = month,
                          day = day)) |>
  group_by(date) |>
  count() |>
  ggplot(aes(x = date, y = n)) +
  geom_line() +
  ggthemes::theme_fivethirtyeight() +
  labs(title = "Cancelled flight numbers show spikes on certain days",
       subtitle = "There is consistent cancellation in December - may be due to snowstorms!") +
  theme(
    plot.background = element_rect(fill = "white"), 
    panel.background = element_rect(fill = "white", colour = "white")
    )
```

```{r}
#| label: fig-q3b-ex3
#| code-fold: true
#| fig-width: 10

mths_lab = c("Jan", "Feb", "Mar", "Apr",
             "May", "Jun", "Jul", "Aug",
             "Sep", "Oct", "Nov", "Dec")
gridExtra::grid.arrange(
  flights |>
    filter(is.na(dep_time)) |>
    group_by(month) |>
    count() |>
    ggplot(aes(x = month, y = n)) +
    geom_line() +
    ggthemes::theme_fivethirtyeight() +
    labs(y = "No. of cancelled flights",
         title = "Flight cancellations occur most \nin a few months",
         subtitle = "December-Feruary, June-July see maximum cancelled flights. \nOctober-November have the least cancellations") +
    scale_x_continuous(breaks = 1:12,
                       labels = mths_lab) +
    theme(title = element_text(size = 8)) +
    theme(
      plot.background = element_rect(fill = "white"), 
      panel.background = element_rect(fill = "white", colour = "white")
    ),
  
  flights |>
    filter(is.na(dep_time)) |>
    group_by(day) |>
    count() |>
    ggplot(aes(x = day, y = n)) +
    geom_line() +
    geom_point(col = "darkgrey", size = 2) +
    ggthemes::theme_fivethirtyeight() +
    labs(y = "No. of cancelled flights",
         title = "Flight cancellations spike on 8th-9th days \nof the months",
         subtitle = "This is unlikely to be a pattern since \nthis is a sum, influenced by a few high values") + 
    scale_x_continuous(breaks = seq(1, 31, 5)) +
    theme(title = element_text(size = 8)) +
    theme(
      plot.background = element_rect(fill = "white"), 
      panel.background = element_rect(fill = "white", colour = "white")
    ),

ncol = 2)
```

The following @fig-3c-ex3 depicts the connection between the proportion of cancelled flights and the average delay of non-cancelled flights. It shows that there is high average delay on the days where there are more cancelled flights, perhaps because bad weather causes both.

Note: Here, I used `geom_smooth()` instead of `geom_line()` to make the pattern more easily perceptible.

```{r}
#| label: fig-3c-ex3
#| fig-cap: "Correlation between proportion of cancelled flights and the average delay of non-cancelled flights"
#| code-fold: true

coeff = 0.15

flights |>
  mutate(date = make_date(year = year,
                          month = month,
                          day = day)) |>
  group_by(month, date) |>
  summarise(
    n = n(),
    cancelled = sum(is.na(dep_time)),
    prop_cancelled = sum(is.na(dep_time)) / n(),
    avg_delay = mean(dep_delay, na.rm = TRUE)
  ) |>
  ggplot(aes(x = date)) +
  geom_smooth(aes(y = prop_cancelled * 100), 
              method = "loess",
              span = coeff,
              col = "red",
              se = FALSE) +
  geom_smooth(aes(y = avg_delay), , 
              method = "loess",
              span = coeff,
              col = "blue",
              se = FALSE) +  
  theme_minimal() +
  scale_y_continuous(
    name = "Percentage Cancelled Flights (%)",
    sec.axis = sec_axis(trans = ~ .*0.5,
                        name = "Avg. Delay (min.)")) +
  labs(x = NULL) +
  theme(axis.text.y.left = element_text(color = "red"),
        axis.title.y.left = element_text(color = "red"),
        axis.text.y.right = element_text(color = "blue"),
        axis.title.y.right = element_text(color = "blue")) +
  labs(title = "Flight Cancellations and average delays are correlated",
       subtitle = "Higher average delay occurs on same days as more flight cancellations")
```

# **13.4.4 Exercises**

## Question 1

**What will `sum(is.na(x))` tell you? How about `mean(is.na(x))`?**

The expression `sum(is.na(x))` tells us the number of missing values in the vector `x`. The expression `mean(is.na(x))` tells us the proportion of missing values in the vector `x` .

This is because `is.na(x)` is a function or operation used to determine which elements of a vector or data structure `x` are missing or NA (Not Available) values. NA values typically represent missing or undefined data points. Here's what the two expressions you provided mean:

1.  `sum(is.na(x))`:

    -   This expression will count the number of NA (missing) values in the vector or data structure `x`. It calculates the total count of NA values in the entire dataset.

    -   The result will be an integer representing the count of NA values.

2.  `mean(is.na(x))`:

    -   This expression will calculate the proportion of NA (missing) values in the vector or data structure `x`. It calculates the average of a binary vector where each element is either 1 (if NA) or 0 (if not NA).

    -   The result will be a numeric value between 0 and 1, representing the fraction of missing values in the dataset. It can be interpreted as the percentage of missing values when multiplied by 100.

Here's a simple example in R to illustrate these concepts:

```{r}
# Sample vector with missing values 
x <- c(1, NA, 3, NA, 5, 6)  

# Count of missing values 
count_missing <- sum(is.na(x)) 
cat("Count of missing values:", count_missing, "\n")  

# Proportion of missing values 
prop_missing <- mean(is.na(x)) 
cat("Proportion of missing values:", prop_missing, "\n")
```

## Question 2

**What does [`prod()`](https://rdrr.io/r/base/prod.html) return when applied to a logical vector? What logical summary function is it equivalent to? What does [`min()`](https://rdrr.io/r/base/Extremes.html) return when applied to a logical vector? What logical summary function is it equivalent to? Read the documentation and perform a few experiments.**

```{r}
#| collapse: true

# A logical vector with random TRUE and FALSE
random <- sample(c(TRUE, FALSE),
            size = 10,
            replace = TRUE)
random
# A logical vector with all TRUE
all_true <- rep(TRUE, 10)
all_true
# A logical vector with all FALSE
all_false <- rep(FALSE, 10)
all_false

prod(random)
prod(all_true)
prod(all_false)

min(random)
min(all_true)
min(all_false)
```

In R, when we apply the `prod()` function to a logical vector, it treats `TRUE` as 1 and `FALSE` as 0, and then computes the product of the elements in the vector. Essentially, it multiplies all the elements together. This can be useful when we want to check if all elements in a logical vector are `TRUE`, as the product will be 1 if all are `TRUE` and 0 if any of them is `FALSE`.

This is equivalent to using the `all()` function, which checks if all elements in a logical vector are `TRUE`. The `all()` function returns `TRUE` if all elements are `TRUE` and `FALSE` otherwise.

Now, when we apply the `min()` function to a logical vector, it also treats `TRUE` as 1 and `FALSE` as 0, and then computes the minimum value. Since 0 represents `FALSE` and 1 represents `TRUE`, the minimum value in a logical vector is `FALSE` (0). Therefore, when we use `min()` on a logical vector with even one value `FALSE`, it will return `FALSE`.

In summary, `prod()` and `min()` applied to logical vectors have specific behavior related to the interpretation of `TRUE` and `FALSE`, and they are equivalent to the `all()`.

Note: `max()` will act as equivalen to the `any()` function.
