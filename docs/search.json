[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Solutions: R for Data Science (2e)",
    "section": "",
    "text": "Author: Aditya Dahiya\nThis website displays the solutions for the exercises in the book R for Data Science, 2nd Edition.\n\n\n\nR for Data Science (2nd Edition)"
  },
  {
    "objectID": "index.html#solutions-for-the-book-r-for-data-science-2nd-edition",
    "href": "index.html#solutions-for-the-book-r-for-data-science-2nd-edition",
    "title": "Solutions: R for Data Science (2e)",
    "section": "",
    "text": "Author: Aditya Dahiya\nThis website displays the solutions for the exercises in the book R for Data Science, 2nd Edition.\n\n\n\nR for Data Science (2nd Edition)"
  },
  {
    "objectID": "Chapter29.html",
    "href": "Chapter29.html",
    "title": "Chapter 29",
    "section": "",
    "text": "Create a new Quarto document using File &gt; New File &gt; Quarto Document. Read the instructions. Practice running the chunks individually. Then render the document by clicking the appropriate button and then by using the appropriate keyboard short cut. Verify that you can modify the code, re-run it, and see modified output.\n\n\nThe document has been created. Some of the chunks are as follows:\n\n\nlibrary(tidyverse)\n\n\ndiamonds |&gt; \n  filter(carat &gt; 2) |&gt;\n  ggplot(mapping = aes(x=carat, y=price,\n                       color = color)) +\n  geom_point(alpha = 0.5) + \n  #scale_y_continuous(trans = \"log\") +\n  geom_smooth(se=FALSE) + \n  scale_color_brewer(palette = 2)\n\n\n\n\n\nVerifying that the code can be modified and re-run:–\n\n\ndiamonds |&gt; \n  filter(carat &gt; 2) |&gt;\n  filter (carat &lt; 3) |&gt;\n  filter (price &gt; 10000) |&gt;\n  ggplot(mapping = aes(x=carat, y=price,\n                       color = color)) +\n  geom_point(alpha = 0.3) + \n  scale_y_continuous(trans = \"log\") +\n  geom_smooth(se=FALSE) + \n  scale_color_brewer(palette = 4) +\n  theme_minimal() +\n  labs(title = \"Plot of relation between Carat and Price\",\n       subtitle = \"For different colours of diamonds\",\n       y = \"Price (in $)\", x = \"Carat\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nCreate one new Quarto document for each of the three built-in formats: HTML, PDF and Word. Render each of the three documents. How do the outputs differ? How do the inputs differ? (You may need to install LaTeX in order to build the PDF output — RStudio will prompt you if this is necessary.)\n\nThe outputs are different in the following ways:--\n\nThe output text and code are same, but rendering to PDF takes more time than Word. HTML rendering seems to be the fastest.\nPDF and MS Word cannot incorporate interactive graphics, while HTML offers interactivity.\nThe size of the PDF document is the largest, followed by MS Word document, while the HTML uses the least disk space."
  },
  {
    "objectID": "Chapter29.html#nd-level-header",
    "href": "Chapter29.html#nd-level-header",
    "title": "Chapter 29",
    "section": "2nd Level Header",
    "text": "2nd Level Header\n\n3rd Level Header"
  },
  {
    "objectID": "Chapter29.html#lists",
    "href": "Chapter29.html#lists",
    "title": "Chapter 29",
    "section": "Lists",
    "text": "Lists\n\nBulleted list item 1\nItem 2\n\nItem 2a\nItem 2b\n\n\n\nNumbered list item 1\nItem 2. The numbers are incremented automatically in the output.\n\n\nLinks and Images\nhttps://example.com/\nlinked phrases\n\n\n\nCredits: Nick Tierney's (mostly) rstats blog\n\n\nTables\n\nMy First Table in Quarto\n\n\nFirst Header\nSecond Header\n\n\n\n\nContent Cell 1.1\nContent Cell 2.1\n\n\nContent Cell 1.2\nContent Cell 2.2\n\n\nContent Cell 1.3\nContent Cell 2.3\n\n\n\n\nUsing the visual editor, insert a code chunk using the Insert menu and then the insert anything tool.\nHere, I am inserting a code chunk using simple the “/” key, and then selecting R-code option:--\n\nprint(\"Hello World\")\n\n[1] \"Hello World\"\n\n\nUsing the visual editor, figure out how to:\n\nAdd a footnote.\nYou can add a foot note by selecting the menu Insert –&gt; Footnote; or, by using Ctrl+Shift+7. Here is an example.1\nAdd a horizontal rule.\nYou can add a foot note by selecting the menu Insert –&gt; Horizontal Rule. Here is an example:--\n\nAdd a block quote.\nYou can add a foot note by selecting the menu Format –&gt; Block quote. Here is how we add a block quote:-\n\nA block quote is a long quote formatted as a separate “block” of text. Instead of using quotation marks, you place the quote on a new line, and indent the entire quote to mark it apart from your own words2\n\n\nIn the visual editor, go to Insert &gt; Citation and insert a citation to the paper titled Welcome to the Tidyverse using its DOI (digital object identifier), which is 10.21105/joss.01686. Render the document and observe how the reference shows up in the document. What change do you observe in the YAML of your document?\n\nLet us first add some text from the paper, so that we can use a citation:---\n\nAt a high level, the tidyverse is a language for solving data science challenges with R code. Its primary goal is to facilitate a conversation between a human and a computer about data. Less abstractly, the tidyverse is a collection of R packages that share a high-level design philosophy and low-level grammar and data structures, so that learning one package makes it easier to learn the next. (Wickham et al. 2019)\n\nOnce we render the document, the citation shows up in the very end of the HTML webpage rendered. It is displayed just above the footnotes. The YAML header of the document, when viewed in the “Source” displays an additional line bibliography: references.bib."
  },
  {
    "objectID": "Chapter29.html#footnotes",
    "href": "Chapter29.html#footnotes",
    "title": "Chapter 29",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is a sample footnote to answer the Question 3(a) of the 29.3.1 Exercises within the Chapter 29 “Quarto” of the Book “R for Data Science, 2nd Edition” by Wickham, Cetinkaya-Rundel & Grolemund.↩︎\nSource: Scribbr.com. What is a block quote?↩︎\nI use Ctrl + Shift + 7 to create a footnote here.↩︎\nThis is a test footnote I wrote in the Source Editor↩︎"
  },
  {
    "objectID": "solutions.html",
    "href": "solutions.html",
    "title": "Solutions",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nTitle\n\n\nSubtitle\n\n\nDate\n\n\nAuthor\n\n\n\n\n\n\nChapter 9\n\n\nWorkflow: getting help\n\n\nAug 13, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 8\n\n\nData Import\n\n\nAug 10, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 7\n\n\nundefined\n\n\nAug 8, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 6\n\n\nData tidying\n\n\nAug 5, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 5\n\n\nWorkflow: code style\n\n\nAug 2, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 4\n\n\nData Transformation\n\n\nJul 29, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 30\n\n\nQuarto Formats\n\n\nJul 25, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 3\n\n\nWorkflow: Basics\n\n\nJul 29, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 29\n\n\nQuarto\n\n\nJul 25, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 21\n\n\nSpreadsheets\n\n\nAug 15, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 2\n\n\nData Visualization\n\n\nJul 29, 2023\n\n\nAditya Dahiya\n\n\n\n\nChapter 10\n\n\nLayers\n\n\nAug 22, 2023\n\n\nAditya Dahiya\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome to the quirky realm of Aditya Dahiya, your friendly neighborhood Indian Administrative Service (IAS) officer, currently working as the Director and Special Secretary in the Government of Haryana, India. Amidst the daily avalanche of files and meetings that could rival a paper mountain, Aditya somehow manages to sneak in quality time with his true loves: data visualization and health financing data. Think of him as your data-wrangling, file-taming, bureaucracy-battling guide with a slightly skewed sense of humor. Need more bureaucratic banter or data insights? Connect with Aditya on LinkedIn or shoot him an email – he promises it won’t be as formal as a government memo!"
  },
  {
    "objectID": "Ch29-6-3-1-3.html",
    "href": "Ch29-6-3-1-3.html",
    "title": "Chapter 29: Exercise 29.6.3.3",
    "section": "",
    "text": "3. Change the size of the figure with the following chunk options, one at a time, render your document, and describe how the figure changes.\n\nHow the figure changes with `fig-width: 6`\n\n\nlibrary(tidyverse)\ndiamonds |&gt;\n  filter(carat &lt;= 2.5) |&gt;\n      ggplot(aes(x = carat)) + \n        geom_freqpoly(binwidth = 0.01) +\n        theme_light() +\n        labs(x=\"Diamond Carat Size\", y = \"Number of Diamonds\")\n\n\n\n\nFigure 1: Plot with width fixed at 10\n\n\n\n\n\nHow the figure changes with `fig-height: 3`\n\n\ndiamonds |&gt;\n  filter(carat &lt;= 2.5) |&gt;\n      ggplot(aes(x = carat)) + \n        geom_freqpoly(binwidth = 0.01) +\n        theme_light() +\n        labs(x=\"Diamond Carat Size\", y = \"Number of Diamonds\")\n\n\n\n\nFigure 2: Plot with height fixed at 10\n\n\n\n\n\nHow the figure changes with `out-width: \"100%\"`\n\n\ndiamonds |&gt;\n  filter(carat &lt;= 2.5) |&gt;\n      ggplot(aes(x = carat)) + \n        geom_freqpoly(binwidth = 0.01) +\n        theme_light() +\n        labs(x=\"Diamond Carat Size\", y = \"Number of Diamonds\")\n\n\n\n\nFigure 3: Plot with output width at 100%\n\n\n\n\n\nHow the figure changes with `out-width: \"20%\"`\n\n\ndiamonds |&gt;\n  filter(carat &lt;= 2.5) |&gt;\n      ggplot(aes(x = carat)) + \n        geom_freqpoly(binwidth = 0.01) +\n        theme_light() +\n        labs(x=\"Diamond Carat Size\", y = \"Number of Diamonds\")\n\n\n\n\nFigure 4: Plot with output width at 20%"
  },
  {
    "objectID": "Chapter2.html",
    "href": "Chapter2.html",
    "title": "Chapter 2",
    "section": "",
    "text": "library(tidyverse)\nlibrary(palmerpenguins)\npenguins = penguins\n\n\n2.2.5 Exercises\n\nHow many rows are in penguins? How many columns?\n\nThe number of rows in penguins data-set is 344 and the number of columns is 8\n\nWhat does the bill_depth_mm variable in the penguins data frame describe? Read the help for ?penguins to find out.\n\nFirst, we find out the names of the variables in the penguins data frame in Table 1.\n\nnames(penguins) |&gt;\n  t() |&gt;\n  as_tibble() |&gt;\n  gt::gt()\n\n\n\n\n\nTable 1:  List of variables in the penguins dataset \n  \n    \n    \n      V1\n      V2\n      V3\n      V4\n      V5\n      V6\n      V7\n      V8\n    \n  \n  \n    species\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n  \n  \n  \n\n\n\n\n# Finding the details of the variables.\n# ?penguins\n\nThe variable name bill_depth_mm depicts “a number denoting bill depth (millimeters)”.[Gorman, Williams, and Fraser (2014)](Horst, Hill, and Gorman 2020)\n\nMake a scatter-plot of bill_depth_mm vs. bill_length_mm. That is, make a scatter-plot with bill_depth_mm on the y-axis and bill_length_mm on the x-axis. Describe the relationship between these two variables.\n\nThe scatter-plot is depicted below.\n\npenguins |&gt;\n  ggplot(mapping = aes(x = bill_length_mm,\n                       y = bill_depth_mm,\n                       col = species)) +\n  geom_point() +\n  geom_smooth(se = FALSE,\n              method = \"lm\") +\n  theme_classic() +\n  labs(x = \"Bill Length (mm)\", y = \"Bill Depth (mm)\")\n\n\n\n\nFigure 1: Scatterplot of relation between Bill Length and Bill Depth\n\n\n\n\nWe now test the correlations, and create a beautiful table using gt (Iannone et al. 2023)and gtExtras packages.(Mock 2022)\n\n# Checking the correlation between the two variables\ntest1 = function(x) {cor.test(x$bill_length_mm, x$bill_depth_mm)$estimate}\n\n# An empty data-frame to collect results\ndf = tibble(Penguins = NA,\n            Correlation = NA,\n            .rows = 4)\n# Finding Correlation by each penguin variety\nfor (y in 1:3) {\n  c = penguins |&gt;\n      filter(species == unique(penguins$species)[y]) |&gt;\n      test1() |&gt;\n      format(digits = 2)\n  df[y,2] = c\n  df[y,1] = unique(penguins$species)[y]\n  }\n# Converting the nature of 1st column from factor to character\ndf$Penguins = as.character(df$Penguins)  \n# Storing the overall correlation\ndf[4,1] = \"Overall\"\ndf[4,2] = penguins |&gt; test1() |&gt; format(digits = 2)\n\n# Displaying the result\ngt::gt(df) |&gt;\n  gt::tab_header(title = \"Correlation Coefficitents\",\n                 subtitle = \"Between Bill Length & Bill Depth amongst   \n                 different penguins\") |&gt;\n  gtExtras::gt_theme_538() |&gt;\n  gtExtras::gt_highlight_rows(rows = 4, fill = \"#d4cecd\")\n\n\n\n\n\nTable 2:  Correlation Table amongst different types of penguins \n  \n    \n      Correlation Coefficitents\n    \n    \n      Between Bill Length & Bill Depth amongst   \n                 different penguins\n    \n    \n      Penguins\n      Correlation\n    \n  \n  \n    Adelie\n0.39\n    Gentoo\n0.64\n    Chinstrap\n0.65\n    Overall\n-0.24\n  \n  \n  \n\n\n\n\n\nThus, we see that the relation is not apparent on a simple scatter plot, but if we plot a different colour for each species, we observe that there is positive correlation between Bill Length and Bill Depth, in all three species. The strongest correlation is amongst Gentoo and Chinstrap penguins.\n\nWhat happens if you make a scatter-plot of species vs. bill_depth_mm? What might be a better choice of geom?\nIf we make a scatter-plot of species vs. bill_depth_mm, the following happens:-\n\npenguins |&gt;\n  ggplot(mapping = aes(x = species,\n                       y = bill_depth_mm)) +\n  geom_point() +\n  theme_bw() +\n  labs(x = \"Species\", y = \"Bill Depth (mm)\")\n\n\n\n\nFigure 2: Scatter plot of species vs. Bill Depth\n\n\n\n\nThis produces an awkward scatter-plot, since the x-axis variable is discrete, and not continuous. A better choice of geom might be a box-plot, which is a good way to present the relationship between a continuous (Bill Depth) and a categorical (species) variable. which shows that the average Bill Depth (in mm) is lower in Gentoo penguins compared to the other two.\n\npenguins |&gt;\n  ggplot(mapping = aes(x = species,\n                       y = bill_depth_mm)) +\n  geom_boxplot() +\n  theme_bw() +\n  labs(x = \"Species\", y = \"Bill Depth (mm)\")\n\n\n\n\nFigure 3: Box-plot of species vs. Bill Depth\n\n\n\n\nWhy does the following give an error and how would you fix it?\nggplot(data = penguins) +    geom_point()\nThe above code will give an error, because we have only given the data to the ggplot call, but not specified the mapping aesthetics, i.e., the x-axis and y-axis for the scatter plot called by the geom_point() . We can fix the error as follows in Figure 4 :---\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm)) +\n  geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 4: Corrected code to display the plot\n\n\n\n\nWhat does the na.rm argument do in geom_point()? What is the default value of the argument? Create a scatterplot where you successfully use this argument set to TRUE.\nWithin the function geom_point() the na.rm argument can do one of the two things. If it is set to FALSE , as it is by default, then the missing values are removed but the following warning message is displayed:–\nWarning message: \nRemoved 2 rows containing missing values (`geom_point()`)\nBut, if it is set to na.rm = TRUE, then the missing values are silently removed. Here’s the code with na.rm = TRUE to produce Figure 5 :---\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm)) +\n  geom_point(na.rm = TRUE)\n\n\n\n\nFigure 5: Corrected code to display the plot with na.rm = TRUE\n\n\n\n\nAdd the following caption to the plot you made in the previous exercise: “Data come from the palmerpenguins package.” Hint: Take a look at the documentation for labs().\nThe caption is added here with the labs function with ggplot function below in (fi?)\n\nggplot(data = penguins,\n       mapping = aes(x = bill_depth_mm,\n                     y = bill_length_mm)) +\n  geom_point(na.rm = TRUE) +\n  labs(caption = \"Data come from the palmerpenguins package.\")\n\n\n\n\nFigure 6: Plot with a caption added in ggplot call itself\n\n\n\n\nRecreate the following visualization. What aesthetic should bill_depth_mm be mapped to? And should it be mapped at the global level or at the geom level?\n\npenguins |&gt;\n  ggplot(mapping = aes(x = flipper_length_mm,\n                       y = body_mass_g)) + \n  geom_point(mapping = aes(color = bill_depth_mm)) + \n  geom_smooth()\n\n\n\n\nFigure 7: Recreated figure using the ggplot2 code\n\n\n\n\nThe code above recreates the Figure 7. The aesthetic should bill_depth_mm should be mapped the aesthetic colo in the geom_point() function level. It should not be done at the global level, because then it will even be an aesthetic for geom_smooth resulting in multiple smoother lines fitted for each level of bill_depth_mm , and possible result in an error because bill_depth_mm is not a categorical variable or a factor variable with certain distinct categories or levels.\nLuckily, ggplot2 recognizes this error and still produces the same plot by droppin the color aesthetic, i.e., The following aesthetics were dropped during statistical transformation: colour. So, ggplot2 is trying to guess our intentions, and it works, but the code not correct. The wrong code is tested at Figure 8.\n\npenguins |&gt;\n  ggplot(mapping = aes(x = flipper_length_mm,\n                       y = body_mass_g,\n                       color = bill_depth_mm)) + \n  geom_point() + \n  geom_smooth()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFigure 8: The Wrong Code - Recreated figure is the same - but the code is fundamentally flawed\n\n\n\n\nRun this code in your head and predict what the output will look like. Then, run the code in R and check your predictions.\n\nggplot(data = penguins,\n       mapping = aes(x = flipper_length_mm, \n                     y = body_mass_g, \n                     color = island)) +\n  geom_point() +\n  geom_smooth(se = FALSE)\n\nOn visual inspection, I believe this code should create a scatter plot of penguins flipper lengths (on x-axis) vs. body mass (on y-axis), with the dots coloured by islands on the penguins. Further, a smoother line if fitted to show the relationship, with a separate smoother line for each island type. Thus, since we know there are three types of islands, we expect three smoother lines fitted to the plot, without the display of standard error intervals.\nNow, let us check our predictions with the code in the Figure 9 :--\n\n\n\n\n\nFigure 9: Plot generated from running the Code of Question 9\n\n\n\n\nWill these two graphs look different? Why/why not?\n\n# Code 1\nggplot(data = penguins,\n       mapping = aes(x = flipper_length_mm, \n                     y = body_mass_g)) +\n  geom_point() +\n  geom_smooth()\n\n# Code 2\nggplot() +\n  geom_point(data = penguins,\n             mapping = aes(x = flipper_length_mm, \n                           y = body_mass_g)\n  ) +\n  geom_smooth(data = penguins,\n              mapping = aes(x = flipper_length_mm, \n                            y = body_mass_g))\n\nYes, these two graphs should look the same. Since, the data and the aesthetics mapped are the same in both. Only difference is that the second code has redundancy.\nHere’s the visual confirmation for both codes in Figure 10.\n\n\n\n\n\nFigure 10: Comparison of the two plots produced by the codes in Question 10\n\n\n\n\n\n\n\n2.4.3 Exercises\n\nMake a bar plot of species of penguins, where you assign species to the y aesthetic. How is this plot different?\nWhen we assign species to the y-axis, we get a horizontal bar plot, instead of the vertical bar plot given in the textbook. The results are compared in Figure 11 .\n\np1 = penguins |&gt;\n      ggplot(aes(x = species)) +\n      geom_bar() +\n      labs(caption = \"Species on x-axis\")\np2 = penguins |&gt;\n      ggplot(aes(y = species)) +\n      geom_bar() +\n      labs(caption = \"Species on y-axis\")\ngridExtra::grid.arrange(p1, p2, ncol = 2)\n\n\n\n\nFigure 11: Change in figure when species is assigned to y-axis\n\n\n\n\nHow are the following two plots different? Which aesthetic, color or fill, is more useful for changing the color of bars?\nThe output of the two plots is in Figure 12 .\n\ngridExtra::grid.arrange(\n\nggplot(penguins, aes(x = species)) + geom_bar(color = \"red\") +\n  labs(caption = \"Color = Red\"),\n\nggplot(penguins, aes(x = species)) + geom_bar(fill = \"red\") +\n  labs(caption = \"Fill = Red\"),\n\nncol = 2)\n\n\n\n\nFigure 12: The two plots produced by the code given, with red color vs. red fill\n\n\n\n\nThe two plots are different in where the colour red appears. As a color aesthetic, it appears only on the borders. But, as a fill aesthetic, it fills the entire bar(s).\nThus, the aesthetic fill is more useful in changing the colour of the bars.\nWhat does the bins argument in geom_histogram() do?\nThe bins argument tell the number of bins (i.e. number of bars) in the histogram to be plotted. The default value is 30. However, if the binwidth is also specified, then the binwidth argument over-rides the bins argument.\nMake a histogram of the carat variable in the diamonds dataset that is available when you load the tidyverse package. Experiment with different binwidths. What bin-width reveals the most interesting patterns?\n\ng1 = ggplot(diamonds, aes(x=carat)) + \n  geom_histogram(fill = \"white\", color = \"black\") + \n  theme_classic() + labs(x = NULL, y = NULL, \n                         subtitle = \"Default Bindwidth\")\ng2 = ggplot(diamonds, aes(x=carat)) + \n    geom_histogram(fill = \"white\", color = \"black\", \n                   binwidth = 0.1) + \n    theme_classic() + \n    labs(x = NULL, y = NULL, \n         subtitle = \"Bindwidth = 0.1\")\ng3 = ggplot(diamonds, aes(x=carat)) + \n    geom_histogram(fill = \"white\", color = \"black\", \n                   binwidth = 0.2) + \n    theme_classic() + \n    labs(x = NULL, y = NULL, \n         subtitle = \"Bindwidth = 0.2\")  \ng4 = ggplot(diamonds, aes(x=carat)) + \n    geom_histogram(fill = \"white\", color = \"black\", \n                   binwidth = 0.3) + \n    theme_classic() + \n    labs(x = NULL, y = NULL, \n         subtitle = \"Bindwidth = 0.3\")\ng5 = ggplot(diamonds, aes(x=carat)) + \n    geom_histogram(fill = \"white\", color = \"black\", \n                   binwidth = 0.5) + \n    theme_classic() + \n    labs(x = NULL, y = NULL, \n         subtitle = \"Bindwidth = 0.5\")\ng6 = ggplot(diamonds, aes(x=carat)) + \n    geom_histogram(fill = \"white\", color = \"black\", \n                   binwidth = 1) + \n    theme_classic() + \n    labs(x = NULL, y = NULL, \n         subtitle = \"Bindwidth = 1\")\n\ngridExtra::grid.arrange(g1, g2, g3, g4, g5, g6,\n                        ncol = 3, nrow = 2)\n\n\n\n\nFigure 13: Histogram with different bin-widths tried out to select the most relevant one\n\n\n\n\nThus, we see that best binwidth is either the default binwidth chosen by ggplot2 or the bind-width of 0.2 per bin, since it reveals the most interesting patterns.\n\n\n\n2.5.5 Exercises\n\nThe mpg data frame that is bundled with the ggplot2 package contains 234 observations collected by the US Environmental Protection Agency on 38 car models. Which variables in mpg are categorical? Which variables are numerical? (Hint: Type ?mpg to read the documentation for the dataset.) How can you see this information when you run mpg?\nThe code below displays the summary fo the mpg data-set. The following variables are categorical: manufacturer (manufacturer name), model (model name), trans (type of transmission), drv (the type of drive train: front, rear or 4-wheel), fl (fuel type), and class (type of car). The numerical variables are displ (engine displacement, in litres), year (year of manufacture) , cyl (number of cylinders) , cty (city miles per gallon) and hwy (highway miles per gallon). We can see these in the square parenthesis the column titled Variable in the output of the code below .\n\n# Visualize summary of the data frame\nmpg |&gt;\n  summarytools::dfSummary(plain.ascii  = FALSE, \n                          style = \"grid\", \n                          graph.magnif = 0.75, \n                          valid.col = FALSE,\n                          na.col = FALSE,\n                          headings = FALSE) |&gt;\n  view()\n\nIf we simply run mpg , we can still see this information in the R console output, by the terms &lt;chr&gt; (for categorical variables) ; and, &lt;dbl&gt; or &lt;int&gt; (for numerical variables)\n\nmpg\n## # A tibble: 234 × 11\n##    manufacturer model      displ  year   cyl trans drv     cty   hwy fl    class\n##    &lt;chr&gt;        &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n##  1 audi         a4           1.8  1999     4 auto… f        18    29 p     comp…\n##  2 audi         a4           1.8  1999     4 manu… f        21    29 p     comp…\n##  3 audi         a4           2    2008     4 manu… f        20    31 p     comp…\n##  4 audi         a4           2    2008     4 auto… f        21    30 p     comp…\n##  5 audi         a4           2.8  1999     6 auto… f        16    26 p     comp…\n##  6 audi         a4           2.8  1999     6 manu… f        18    26 p     comp…\n##  7 audi         a4           3.1  2008     6 auto… f        18    27 p     comp…\n##  8 audi         a4 quattro   1.8  1999     4 manu… 4        18    26 p     comp…\n##  9 audi         a4 quattro   1.8  1999     4 auto… 4        16    25 p     comp…\n## 10 audi         a4 quattro   2    2008     4 manu… 4        20    28 p     comp…\n## # ℹ 224 more rows\n\nMake a scatterplot of hwy vs. displ using the mpg data frame. Next, map a third, numerical variable to color, then size, then both color and size, then shape. How do these aesthetics behave differently for categorical vs. numerical variables?\n\ng1 = mpg |&gt;\n      ggplot(aes(x = hwy, y = displ)) +\n      geom_point() +\n      theme_minimal() +\n      labs(caption = \"Original Plot\")\n# Using numerical variable 'cty' to map to colour, size\ng2 = mpg |&gt;\n      ggplot(aes(x = hwy, y = displ, color = cty)) +\n      geom_point() +\n      theme_minimal()+\n      labs(caption = \"cty mapped to color\")\ng3 = mpg |&gt;\n      ggplot(aes(x = hwy, y = displ, size = cty)) +\n      geom_point(alpha = 0.5) +\n      theme_minimal()+\n      labs(caption = \"cty mapped to size\")\ng4 = mpg |&gt;\n      ggplot(aes(x = hwy, y = displ, \n                 color = cty, size = cty)) +\n      geom_point() +\n      theme_minimal()+\n      labs(caption = \"cty mapped to size and color\")\ngridExtra::grid.arrange(g1, g2, g3, g4, ncol = 2)\n\n\n\n\nFigure 14: Scatterplots of different kinds for different aesthetic mappings\n\n\n\n\nSo, we see that we can map a numerical variable to color or size aesthetics, and ggplot2 will itself make a scale and display the output with a legend. However, numerical variables (i.e., continuous variables) don’t map to shape aesthetic, as there cannot be any continuum amongst shapes. Accordingly, when mapped to shape, the code throws an error as below:---\n\n# Using numerical variable 'cty' to map to size aesthetic \n  mpg |&gt;\n      ggplot(aes(x = hwy, \n                 y = displ, \n                 shape = cty)) +\n      geom_point()\n\nError in `geom_point()`:\n! Problem while computing aesthetics.\nℹ Error occurred in the 1st layer.\nCaused by error in `scale_f()`:\n! A continuous variable cannot be mapped to the shape aesthetic\nℹ choose a different aesthetic or use `scale_shape_binned()`\n\n\nThus, the shape aesthetic works only with categorical variables, whereas color works with both numerical and categorical variables; and, by definition size aesthetic should be used only with numerical variables (it can work with categorical variables, but then the sizes are assigned arbitrarily to different categories).\nIn the scatter-plot of hwy vs. displ, what happens if you map a third variable to linewidth?\n\nmpg |&gt;\n      ggplot(aes(x = hwy, y = displ,\n                 linewidth = cty)) +\n      geom_point() +\n      theme_minimal()\n\n\n\n\nFigure 15: Experiment with mapping line width to a third variable\n\n\n\n\nAs we see, nothing changes with addition of the linewidth argument in Figure 15 . This is because the linewidth argument “scales the width of lines and polygon strokes.” in ggplot2 documentation. Since we are only plotting point geoms, and no lines, the argument is useless and not used to produce the output.\nWhat happens if you map the same variable to multiple aesthetics?\nWe can map the same variable to multiple aesthetics, and the output will display its variations in all such aesthetics. But it is redundant, and make plot cluttery with too much visual input.\nFor example, Figure 16 shows a poorly understandable plot where class of the vehicle is mapped to size, shape and color. It works, but there’s too much information redundancy.\n\nmpg |&gt;\n  ggplot(aes(x=hwy, y = cty,\n             size = class,\n             color = class,\n             shape = class)) +\n  geom_point(alpha = 0.5) +\n  theme_classic()\n\n\n\n\nFigure 16: A messy plot with Mutliple aesthetics defined by the same variable\n\n\n\n\nMake a scatterplot of bill_depth_mm vs. bill_length_mm and color the points by species. What does adding coloring by species reveal about the relationship between these two variables? What about faceting by species?\nThe Figure 17 shows the importance of coloring or faceting by species. This allows us to detect a fairly strong positive correlation which was not apparent in the simple scatter plot. This, perhaps, can be called an example of negative confounding (Mehio-Sibai et al. 2005) of the relation between bill depth and bill length by the species type.\n\np1 = penguins |&gt;\n  ggplot(mapping = aes(x = bill_length_mm,\n                       y = bill_depth_mm)) +\n  geom_point() +\n  geom_smooth(se = FALSE,\n              method = \"lm\") +\n  theme_classic() +\n  labs(x = \"Bill Length (mm)\", y = \"Bill Depth (mm)\",\n       subtitle = \"No relation is apparent\")\n\np2 = penguins |&gt;\n  ggplot(mapping = aes(x = bill_length_mm,\n                       y = bill_depth_mm,\n                       col = species)) +\n  geom_point() +\n  geom_smooth(se = FALSE,\n              method = \"lm\") +\n  theme_classic() +\n  labs(x = \"Bill Length (mm)\", y = \"Bill Depth (mm)\",\n       subtitle = \"Colouring  by species reveals relations\")\n\np3 = penguins |&gt;\n  ggplot(mapping = aes(x = bill_length_mm,\n                       y = bill_depth_mm)) +\n  geom_point() +\n  geom_smooth(se = FALSE,\n              method = \"lm\") +\n  facet_wrap(~species) +\n  theme_classic() +\n  labs(x = \"Bill Length (mm)\", y = \"Bill Depth (mm)\",\n       subtitle = \"Faceting also reveals the relations\")\n\nlay = rbind(c(1,1,2,2,2),\n            c(3,3,3,3,3))\ngridExtra::grid.arrange(p1, p2, p3, layout_matrix = lay)\n\n\n\n\nFigure 17: Adding color by species reveals a strong relationship\n\n\n\n\nWhy does the following yield two separate legends? How would you fix it to combine the two legends?\n\n\nggplot(data = penguins,   \n       mapping = aes(x = bill_length_mm, \n                     y = bill_depth_mm,      \n                     color = species, \n                     shape = species)) +   \n  geom_point() +   \n  labs(color = \"Species\")\n\nThis code presents a plot with two legends because in the last line, we have forced ggplot2 to name out “Color” legend as the string “Species”. Thus, ggplot2 differentiates between “species” and “Species”.\nWe can correct this issue in either of the following two ways:--\n\nggplot(data = penguins,   \n       mapping = aes(x = bill_length_mm, \n                     y = bill_depth_mm,      \n                     color = species, \n                     shape = species)) +   \n  geom_point()\n\nor,\n\nggplot(data = penguins,   \n       mapping = aes(x = bill_length_mm, \n                     y = bill_depth_mm,      \n                     color = species, \n                     shape = species)) +   \n  geom_point()\n\n\nCreate the two following stacked bar plots. Which question can you answer with the first one? Which question can you answer with the second one?\nThe plots are produced in Figure 18 .\n\ng1 = ggplot(penguins, aes(x = island, \n                     fill = species)) +   \n  geom_bar(position = \"fill\") +\n  labs(subtitle = \"Sub-figure A\")\n\ng2 = ggplot(penguins, aes(x = species, \n                     fill = island)) +   \n  geom_bar(position = \"fill\") +\n  labs(subtitle = \"Sub-figure B\")\n\ngridExtra::grid.arrange(g1, g2, ncol = 2)\n\n\n\n\nFigure 18: The two stacked bar plots produced by the code\n\n\n\n\nThe Sub-Figure A answers the question, that “On each of the three islands, what proportion of penguins belong to which species?”\nThe Sub-Figure B answers the question reg. distribution of the population of each species of penguins, that is, “For each of the penguin species’, what proportion of each species total population is found on which island?”\n\n\n\n2.6.1 Exercises\n\nRun the following lines of code. Which of the two plots is saved as mpg-plot.png? Why?\nggplot(mpg, aes(x = class)) +   \ngeom_bar() \n\nggplot(mpg, aes(x = cty, y = hwy)) +   \ngeom_point() \n\nggsave(\"mpg-plot.png\")\nThe second plot, i.e., the scatter plot is saved into the file “mpg-plot.png” in the working directory, because the function ggsave() saves only the most recent plot into the file.\nWhat do you need to change in the code above to save the plot as a PDF instead of a PNG? How could you find out what types of image files would work in ggsave()?\nTo save the plot as a PDF file, we will need to add the arguments device  = \"pdf\" to the ggsave() function call. We can find out the types of image files that would work by using the help for ggsave() function by running the code ?ggsave at the command prompt.\nThe documentation for the device argument within ggsave() function tells us that following image document types work with it:--\n\na device function (e.g. png), or\none of “eps”, “ps”, “tex” (pictex), “pdf”, “jpeg”, “tiff”, “png”, “bmp”, “svg” or “wmf” (windows only).\n\n\n\n\n\n\n\nReferences\n\nGorman, Kristen B., Tony D. Williams, and William R. Fraser. 2014. “Ecological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).” Edited by André Chiaradia. PLoS ONE 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081.\n\n\nHorst, Allison M, Alison Presmanes Hill, and Kristen B Gorman. 2020. Allisonhorst/Palmerpenguins: V0.1.0. Zenodo. https://doi.org/10.5281/ZENODO.3960218.\n\n\nIannone, Richard, Joe Cheng, Barret Schloerke, Ellis Hughes, Alexandra Lauer, and JooYoung Seo. 2023. “Gt: Easily Create Presentation-Ready Display Tables.” https://CRAN.R-project.org/package=gt.\n\n\nMehio-Sibai, Abla, Manning Feinleib, Tarek A. Sibai, and Haroutune K. Armenian. 2005. “A Positive or a Negative Confounding Variable? A Simple Teaching Aid for Clinicians and Students.” Annals of Epidemiology 15 (6): 421–23. https://doi.org/10.1016/j.annepidem.2004.10.004.\n\n\nMock, Thomas. 2022. “gtExtras: Extending ’Gt’ for Beautiful HTML Tables.” https://CRAN.R-project.org/package=gtExtras."
  },
  {
    "objectID": "Chapter30.html",
    "href": "Chapter30.html",
    "title": "Chapter 30",
    "section": "",
    "text": "library(DT)\nlibrary(tidyverse)\nlibrary(knitr)\n\n\n\nLet us try to create an interactive map in HTML below Figure 1:—̥\n\nlibrary(leaflet)\nleaflet() |&gt;\n  setView(76.801175, 30.761403, zoom = 14) |&gt; \n  addTiles() |&gt;\n  addMarkers(76.801175, 30.761403, \n             popup = \"Haryana Civil Secretariat\")  |&gt;\n  addMarkers(76.803773534,\n             30.752910586,\n             popup = \"Rock Garden\")\n\n\n\n\nFigure 1: A map of Chandigarh, India using Leaflet\n\n\n\n\n\nAn example of using DT for an interactive table is at Figure 2 :---\n\ndiamonds |&gt;\n  filter(carat &gt; 3) |&gt;\n  datatable(colnames = c(\"Carat\", \"Cut\", \"Color\",\n                         \"Clarity\", \"Depth\", \"Table\",\n                         \"Price\", \"X\", \"Y\", \"Z\"),\n            rownames = FALSE)\n\n\n\n\n\nFigure 2: A visually pleasing table produced using DT package"
  },
  {
    "objectID": "Chapter30.html#htmlwidgets",
    "href": "Chapter30.html#htmlwidgets",
    "title": "Chapter 30",
    "section": "",
    "text": "Let us try to create an interactive map in HTML below Figure 1:—̥\n\nlibrary(leaflet)\nleaflet() |&gt;\n  setView(76.801175, 30.761403, zoom = 14) |&gt; \n  addTiles() |&gt;\n  addMarkers(76.801175, 30.761403, \n             popup = \"Haryana Civil Secretariat\")  |&gt;\n  addMarkers(76.803773534,\n             30.752910586,\n             popup = \"Rock Garden\")\n\n\n\n\nFigure 1: A map of Chandigarh, India using Leaflet\n\n\n\n\n\nAn example of using DT for an interactive table is at Figure 2 :---\n\ndiamonds |&gt;\n  filter(carat &gt; 3) |&gt;\n  datatable(colnames = c(\"Carat\", \"Cut\", \"Color\",\n                         \"Clarity\", \"Depth\", \"Table\",\n                         \"Price\", \"X\", \"Y\", \"Z\"),\n            rownames = FALSE)\n\n\n\n\n\nFigure 2: A visually pleasing table produced using DT package"
  },
  {
    "objectID": "Chapter4.html",
    "href": "Chapter4.html",
    "title": "Chapter 4",
    "section": "",
    "text": "4.2.5 Exercises\n\nlibrary(tidyverse) \nlibrary(nycflights13) \nlibrary(gt)\ndata(\"flights\")\n\n\nIn a single pipeline for each condition, find all flights that meet the condition:\n\nHad an arrival delay of two or more hours\n\nflights |&gt;   \n  filter(arr_delay &gt;= 120)\n\n# A tibble: 10,200 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      811            630       101     1047            830\n 2  2013     1     1      848           1835       853     1001           1950\n 3  2013     1     1      957            733       144     1056            853\n 4  2013     1     1     1114            900       134     1447           1222\n 5  2013     1     1     1505           1310       115     1638           1431\n 6  2013     1     1     1525           1340       105     1831           1626\n 7  2013     1     1     1549           1445        64     1912           1656\n 8  2013     1     1     1558           1359       119     1718           1515\n 9  2013     1     1     1732           1630        62     2028           1825\n10  2013     1     1     1803           1620       103     2008           1750\n# ℹ 10,190 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nFlew to Houston (IAH or HOU)\n\nflights |&gt;     \n  filter(dest %in% c(\"IAH\", \"HOU\"))\n\n# A tibble: 9,313 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      623            627        -4      933            932\n 4  2013     1     1      728            732        -4     1041           1038\n 5  2013     1     1      739            739         0     1104           1038\n 6  2013     1     1      908            908         0     1228           1219\n 7  2013     1     1     1028           1026         2     1350           1339\n 8  2013     1     1     1044           1045        -1     1352           1351\n 9  2013     1     1     1114            900       134     1447           1222\n10  2013     1     1     1205           1200         5     1503           1505\n# ℹ 9,303 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nWere operated by United, American, or Delta\n\nflights |&gt;   \n  filter(carrier %in% c(\"UA\", \"AA\", \"DL\"))\n\n# A tibble: 139,504 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      554            600        -6      812            837\n 5  2013     1     1      554            558        -4      740            728\n 6  2013     1     1      558            600        -2      753            745\n 7  2013     1     1      558            600        -2      924            917\n 8  2013     1     1      558            600        -2      923            937\n 9  2013     1     1      559            600        -1      941            910\n10  2013     1     1      559            600        -1      854            902\n# ℹ 139,494 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nDeparted in summer (July, August, and September)\n\nflights |&gt;   \n  filter(month %in% c(7, 8, 9))\n\n# A tibble: 86,326 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     7     1        1           2029       212      236           2359\n 2  2013     7     1        2           2359         3      344            344\n 3  2013     7     1       29           2245       104      151              1\n 4  2013     7     1       43           2130       193      322             14\n 5  2013     7     1       44           2150       174      300            100\n 6  2013     7     1       46           2051       235      304           2358\n 7  2013     7     1       48           2001       287      308           2305\n 8  2013     7     1       58           2155       183      335             43\n 9  2013     7     1      100           2146       194      327             30\n10  2013     7     1      100           2245       135      337            135\n# ℹ 86,316 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nArrived more than two hours late, but didn’t leave late\n\nflights |&gt;     \n  filter(dep_delay &lt;= 0) \n\n# A tibble: 200,089 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      544            545        -1     1004           1022\n 2  2013     1     1      554            600        -6      812            837\n 3  2013     1     1      554            558        -4      740            728\n 4  2013     1     1      555            600        -5      913            854\n 5  2013     1     1      557            600        -3      709            723\n 6  2013     1     1      557            600        -3      838            846\n 7  2013     1     1      558            600        -2      753            745\n 8  2013     1     1      558            600        -2      849            851\n 9  2013     1     1      558            600        -2      853            856\n10  2013     1     1      558            600        -2      924            917\n# ℹ 200,079 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nWere delayed by at least an hour, but made up over 30 minutes in flight\n\nflights |&gt;     \n  filter(dep_delay - arr_delay &gt;= 30) \n\n# A tibble: 20,395 × 19\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      701            700         1     1123           1154\n 2  2013     1     1      820            820         0     1249           1329\n 3  2013     1     1      840            845        -5     1311           1350\n 4  2013     1     1      857            851         6     1157           1222\n 5  2013     1     1      909            810        59     1331           1315\n 6  2013     1     1     1025            951        34     1258           1302\n 7  2013     1     1     1153           1200        -7     1450           1529\n 8  2013     1     1     1245           1249        -4     1722           1800\n 9  2013     1     1     1610           1615        -5     1913           1948\n10  2013     1     1     1625           1550        35     2054           2050\n# ℹ 20,385 more rows\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\n\nSort flights to find the flights with longest departure delays. Find the flights that left earliest in the morning.\nThe top 5 flights that has the longest departure delays are shown in Table 1 .\n\nflights |&gt;   \n  arrange(desc(dep_delay)) |&gt;   \n  head(n = 5) |&gt;\n  select(year, month, day, dep_time, sched_dep_time,\n         dep_delay, carrier, flight, origin) |&gt;\n  mutate(Day = as_date(paste(year, month, day, sep = \"-\"))) |&gt;\n  select(-year, -month, -day) |&gt;\n  relocate(Day, .before = dep_time) |&gt;\n  gt::gt()\n\n\n\n\n\nTable 1:  5 Flights with longest departure delays \n  \n\n    \n      Day\n      dep_time\n      sched_dep_time\n      dep_delay\n      carrier\n      flight\n      origin\n    \n  \n  \n    2013-01-09\n641\n900\n1301\nHA\n51\nJFK\n    2013-06-15\n1432\n1935\n1137\nMQ\n3535\nJFK\n    2013-01-10\n1121\n1635\n1126\nMQ\n3695\nEWR\n    2013-09-20\n1139\n1845\n1014\nAA\n177\nJFK\n    2013-07-22\n845\n1600\n1005\nMQ\n3075\nJFK\n  \n\n\n\n\n\n\n\nSort flights to find the fastest flights. (Hint: Try including a math calculation inside of your function.)\nThe speed of a flight can be found as distance/air_time . The Table 2 displays the 5 fastest flights.\n\nflights |&gt;\n  arrange(desc(distance/air_time)) |&gt;\n  slice_head(n=5) |&gt;\n  select(year, month, day, distance, air_time,\n         carrier, flight, origin, dest) |&gt;\n  gt()\n\n\n\n\n\nTable 2:  5 fastest Flights (by speed) \n  \n\n    \n      year\n      month\n      day\n      distance\n      air_time\n      carrier\n      flight\n      origin\n      dest\n    \n  \n  \n    2013\n5\n25\n762\n65\nDL\n1499\nLGA\nATL\n    2013\n7\n2\n1008\n93\nEV\n4667\nEWR\nMSP\n    2013\n5\n13\n594\n55\nEV\n4292\nEWR\nGSP\n    2013\n3\n23\n748\n70\nEV\n3805\nEWR\nBNA\n    2013\n1\n12\n1035\n105\nDL\n1902\nLGA\nPBI\n  \n\n\n\n\n\n\n\nWas there a flight on every day of 2013?\nYes, there was a flight on every day of 2013, because using distinct() function, we find that there are 365 unique combinations of year , month , and day .\n\nflights |&gt;\n  distinct(year, month, day) |&gt;\n  count() |&gt;\n  as.numeric()\n\n[1] 365\n\n\nWhich flights traveled the farthest distance? Which traveled the least distance?\nThe top 5 flights by the farthest distance traveled are shown in Table 3 .\n\nflights |&gt;\n  arrange(desc(distance)) |&gt;\n  select(origin, dest, distance, air_time, carrier) |&gt;\n  # Distinct added to remove same flight (on different days) repeating in top 5\n  distinct(origin, dest, .keep_all = TRUE) |&gt;\n  slice_head(n = 5) |&gt;\n  gt()\n\n\n\n\n\nTable 3:  5 longest distance flights \n  \n\n    \n      origin\n      dest\n      distance\n      air_time\n      carrier\n    \n  \n  \n    JFK\nHNL\n4983\n659\nHA\n    EWR\nHNL\n4963\n656\nUA\n    EWR\nANC\n3370\n418\nUA\n    JFK\nSFO\n2586\n366\nUA\n    JFK\nOAK\n2576\n330\nB6\n  \n\n\n\n\n\n\n\nThe 5 flights with least distance traveled are shown in\n\nflights |&gt;\n  arrange(distance) |&gt;\n  select(origin, dest, distance, air_time, carrier) |&gt;\n  # Distinct added to remove same flight (which runs\n  # on different days) repeating in top 5\n  distinct(origin, dest, .keep_all = TRUE) |&gt;\n  slice_head(n = 5) |&gt;\n  gt()\n\n\n\n\n\nTable 4:  5 shortest distance flights \n  \n\n    \n      origin\n      dest\n      distance\n      air_time\n      carrier\n    \n  \n  \n    EWR\nLGA\n17\nNA\nUS\n    EWR\nPHL\n80\n30\nEV\n    JFK\nPHL\n94\n35\n9E\n    LGA\nPHL\n96\n32\nUS\n    EWR\nBDL\n116\n25\nEV\n  \n\n\n\n\n\n\n\nDoes it matter what order you used filter() and arrange() if you’re using both? Why/why not? Think about the results and how much work the functions would have to do.\nAlthough, in terms of output received, it does not matter in which order we use them, because when we run the function filter() it removes the rows not required, but leaves the arrangement-ordering the same, i.e. the remaining rows move up.\nHowever, using arrange() before filter() means R will have to arrange all the rows, and then we filter out only a few rows - thus meaning that more work will have to be done computationally.\nFor computational efficiency, it would be better if we use filter() first, then run arrange() only on the subset of rows remaining.\nHere’s the proof for this, using system.time() function in R which tells how much time does an R expression take to run. Here, I compare both functions using the logical operator &gt; (greater than). The elapsed time comes TRUE, meaning that arranging first, and then filtering takes more time.\n\nsystem.time( flights |&gt;\n  arrange(distance) |&gt;\n  filter(air_time &lt; 60)\n  ) &gt; system.time(\n  flights |&gt;\n    filter(air_time &lt; 60) |&gt;\n    arrange(distance)\n)\n\n user.self   sys.self    elapsed user.child  sys.child \n     FALSE      FALSE       TRUE         NA         NA \n\n\n\n\n\n4.3.5 Exercises\n\nCompare dep_time, sched_dep_time, and dep_delay. How would you expect those three numbers to be related?\nWe would expect dep_delay = dep_time - sched_dep_time . Let us check this in the code, as well.\n\nflights |&gt;\n  mutate(calc = dep_time - sched_dep_time) |&gt;\n  mutate(match = calc == dep_delay, .keep = \"used\") |&gt;\n  summarise(Matching = sum(match, na.rm = TRUE),\n            Total = count(flights)) |&gt;\n  mutate(Percentage = 100*Matching/Total)\n\n# A tibble: 1 × 3\n  Matching Total$n Percentage$n\n     &lt;int&gt;   &lt;int&gt;        &lt;dbl&gt;\n1   228744  336776         67.9\n\n\nThe results indicate that 67.9% of the time, the comparison works out as expected. For others, there might be missing data issues (hence, we had to use na.rm = TRUE) or, any other data error.\nBrainstorm as many ways as possible to select dep_time, dep_delay, arr_time, and arr_delay from flights.\n\n# Using variable names\nflights |&gt; \n  select(dep_time, dep_delay, arr_time, arr_delay)\n\n# Using starts_with()\nflights |&gt; \n  select(starts_with(\"dep\"), starts_with(\"arr\"))\n\n# Using column numbers\nflights |&gt;\n  select(4,6,7,9)\n\n# Using from, to, ie., \":\" along with \"!\" to remove sched_ \nflights |&gt; \n  select(dep_time:arr_delay) |&gt;\n  select(!starts_with(\"sched\"))\n\n# Using column numbers with :\nflights |&gt;\n  select(4:9, -5, -8)\n\nWhat happens if you specify the name of the same variable multiple times in a select() call?\nIf we specify the name of the same variable multiple times, the dplyr package understands the mistake, and only produces one copy of the variable in the output. The place of the variable is the one that first appears in the code within the select() function. Here are two examples:---\n\nflights |&gt;\n  select(dep_time, dep_time) |&gt;\n  slice_head(n=2)\n\n# A tibble: 2 × 1\n  dep_time\n     &lt;int&gt;\n1      517\n2      533\n\nflights |&gt;\n  select(dep_time:dep_delay, sched_dep_time) |&gt;\n  slice_head(n=2)\n\n# A tibble: 2 × 3\n  dep_time sched_dep_time dep_delay\n     &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;\n1      517            515         2\n2      533            529         4\n\n\nWhat does the any_of() function do? Why might it be helpful in conjunction with this vector?\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\nThe two functions, any_of() and all_of() are called selection helpers. They help select variables contained in a character vector, such as variables .\nIn present scenario, the any_of() can be used with variables vector to select these columns (or, remove these columns) from the flights data-set, as shown in the code below:---\n\nvariables &lt;- c(\"year\", \"month\", \"day\", \"dep_delay\", \"arr_delay\")\n\nflights |&gt;\n  select(any_of(variables)) |&gt;\n  slice_head(n=2)\n\n# A tibble: 2 × 5\n   year month   day dep_delay arr_delay\n  &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  2013     1     1         2        11\n2  2013     1     1         4        20\n\n\nBut, there is a difference between any_of() and all_of() . As shown in R help, all_of() is for strict selection. If any of the variables in the character vector is missing, an error is thrown. But, any_of() doesn’t check for missing variables. It is especially useful with negative selections, when you would like to make sure a variable is removed. Here’s an example to demonstrate:---\n\n# Change \"day\" to \"date\" to delibertely cause a missing variable name\nvariables &lt;- c(\"year\", \"month\", \"date\", \"dep_delay\", \"arr_delay\")\n\n# all_of() should not work\nflights |&gt;\n  select(all_of(variables)) |&gt;\n  slice_head(n=2)\n\nError in `all_of()`:\n! Can't subset columns that don't exist.\n✖ Column `date` doesn't exist.\n\n# any_of() will still work\nflights |&gt;\n  select(any_of(variables)) |&gt;\n  slice_head(n=2)\n\n# A tibble: 2 × 4\n   year month dep_delay arr_delay\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1  2013     1         2        11\n2  2013     1         4        20\n\n\nDoes the result of running the following code surprise you? How do the select helpers deal with upper and lower case by default? How can you change that default? flights |&gt; select(contains(\"TIME\"))\nYes, the running of this code surprises me because generally, R is very picky about upper-case vs. lower-case. Since \"TIME\" is not contained in any variable name, I expected it to throw an error. Yet, it returns all variables which contain \"time\".\nThus, this means that the following select helpers from tidyselect package ignore the case of the match provided by default.\n\nstarts_with(): Starts with an exact prefix.\nends_with(): Ends with an exact suffix.\ncontains(): Contains a literal string.\nmatches(): Matches a regular expression.\n\nTo change this, we can set the argument ignore.case = FALSE.\nRename air_time to air_time_min to indicate units of measurement and move it to the beginning of the data frame.\nThe following code does the job, as shown in the output:--\n\nflights |&gt;\n  rename(air_time_min = air_time) |&gt;\n  relocate(air_time_min)\n\n# A tibble: 336,776 × 19\n   air_time_min  year month   day dep_time sched_dep_time dep_delay arr_time\n          &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;\n 1          227  2013     1     1      517            515         2      830\n 2          227  2013     1     1      533            529         4      850\n 3          160  2013     1     1      542            540         2      923\n 4          183  2013     1     1      544            545        -1     1004\n 5          116  2013     1     1      554            600        -6      812\n 6          150  2013     1     1      554            558        -4      740\n 7          158  2013     1     1      555            600        -5      913\n 8           53  2013     1     1      557            600        -3      709\n 9          140  2013     1     1      557            600        -3      838\n10          138  2013     1     1      558            600        -2      753\n# ℹ 336,766 more rows\n# ℹ 11 more variables: sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;,\n#   flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt;\n\n\nWhy doesn’t the following work, and what does the error mean?\nflights |&gt;    \n  select(tailnum) |&gt;    \n  arrange(arr_delay) \n\n#&gt; Error in `arrange()`: #&gt; ℹ In argument: `..1 = arr_delay`.\n#&gt; Caused by error: #&gt; ! object 'arr_delay' not found\nThe above code does not work because the select(tailnum) has removed all other variables (columns) from the tibble. Thus, when arrange(arr_delay) runs, it is unable to find any variable by the name of arr_delay in the tibble.\nThe error means that object (i.e. variable) 'arr_delay' has not been found in the tibble by the arrange() function.\n\n\n\n4.5.7 Exercises\n\nWhich carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs. bad carriers? Why/why not? (Hint: think about flights |&gt; group_by(carrier, dest) |&gt; summarize(n()))\nThe overall carrier with worst average delays is F9, as seen from the code below:\n\nflights |&gt;\n  group_by(carrier) |&gt;\n  summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) |&gt;\n  slice_max(order_by = avg_delay, n = 1)\n\n# A tibble: 1 × 2\n  carrier avg_delay\n  &lt;chr&gt;       &lt;dbl&gt;\n1 F9           21.9\n\n\nYes, we can disentangle the effect of bad airports vs. bad carriers using the code below:---\n\nflights |&gt;\n  group_by(dest, carrier) |&gt;\n  summarise(avg_delay = mean(arr_delay, na.rm = TRUE)) |&gt;\n  # taking the highest average delay flight at each airport\n  slice_max(order_by = avg_delay, n = 1) |&gt;\n  ungroup() |&gt;\n  # for each airline, summarize the number of airports where it is\n  # the most delayed airline\n  summarise(n = n(), .by = carrier) |&gt;\n  slice_head(n=5)|&gt;\n  arrange(desc(n)) |&gt;\n  rename(Carrier = carrier,\n         `Number of Airports` = n) |&gt;\n  gt()\n\n\n\n\n\nTable 5:  The airlines which have highest average delay at the maximum number\nof Airports \n  \n\n    \n      Carrier\n      Number of Airports\n    \n  \n  \n    EV\n42\n    B6\n20\n    UA\n14\n    AA\n6\n    FL\n2\n  \n\n\n\n\n\n\n\nFind the flights that are most delayed upon departure from each destination.\nWe can use the following codes (either one works, and the code checks this equality of results) to find the flight with highest departure delay (dep_delay ) for each destination (Table 6).\n\n\nCode\n# Option 1: Group by \"dest\" and then use slice_max\na = flights |&gt;\n  group_by(dest) |&gt;\n  slice_max(n=1, order_by = dep_delay, na_rm = TRUE) |&gt;\n  select(dest, flight, origin, dep_delay, month, day) |&gt;\n  arrange(desc(dep_delay), desc(flight))\n# Option 2: Directly use slice_max() with \"by\" argument\nb = flights |&gt;\n  slice_max(n=1, order_by = dep_delay, by = dest, na_rm = TRUE) |&gt;\n  select(dest, flight, origin, dep_delay, month, day) |&gt;\n  arrange(desc(dep_delay), desc(flight))\n# Check results\nsum(a != b)\n\n\n[1] 0\n\n\nCode\n# Display results\nb |&gt; \n  slice_head(n=5) |&gt; \n  gt() |&gt;\n  cols_label(dest = \"Destination\", \n             flight = \"Flight\", \n             origin = \"Origin Airport\",\n             dep_delay = \"Departure Depay (minutes)\", \n             month = \"Month\", \n             day = \"Date\") |&gt;\n  cols_align(align = \"center\")\n\n\n\n\n\n\nTable 6:  Flights with highest departure delay; displayed here only for 5\ndestinations highest departure delay \n  \n\n    \n      Destination\n      Flight\n      Origin Airport\n      Departure Depay (minutes)\n      Month\n      Date\n    \n  \n  \n    HNL\n51\nJFK\n1301\n1\n9\n    CMH\n3535\nJFK\n1137\n6\n15\n    ORD\n3695\nEWR\n1126\n1\n10\n    SFO\n177\nJFK\n1014\n9\n20\n    CVG\n3075\nJFK\n1005\n7\n22\n  \n\n\n\n\n\n\n\nHow do delays vary over the course of the day. Illustrate your answer with a plot.\nThe following graph of average delay (on y-axis) plotted against scheduled departure time (on x-axis) shows the overall trend that the average delays rise over the course of the day to hit a peak around 6 pm.\nNote: The scheduled departure time is not accurate in the data-set, since it is written in hhmm format, and thus is not continuous variable. For example, 1:59 am is 159, and then 2:00 am is 200. So there are no values in 60s, 70s, 80s, 90s. I rectified this using mathematical operators %/% and %% to obtain hours and minutes, and then combined them. Now, the result is a smoother graph.\n\nflights |&gt;\n  group_by(sched_dep_time) |&gt;\n  summarise(avg_delay = mean(dep_delay, na.rm = TRUE)) |&gt;\n  mutate(hour = sched_dep_time %/% 100,\n         minute = sched_dep_time %% 100) |&gt;\n  mutate(time_hr = hour + minute/60) |&gt;\n  ggplot(aes(x = time_hr, y = avg_delay)) +\n  geom_line() +\n  geom_smooth(color = \"red\", se = FALSE) +\n  theme_bw() + \n  labs(x = \"Scheduled Departure time (in Hrs.)\",\n       y = \"Average delay in minutes\") +\n  scale_x_continuous(breaks = seq(from = 0, to = 24, by = 4))\n\n\n\nFigure 1: Graph showing average delays over the course of the day at various scheduled times\n\n\n\n\n\nWhat happens if you supply a negative n to slice_min() and friends?\nThe inbuilt R help tells me that “A negative value of n will be subtracted from the group size. For example, n = -2 with a group of 5 rows will select 5 - 2 = 3 rows.”\nHere’s an example to explain. First, I create a tibble a (shown in Table 7) to contain the average departure delay from JFK airport to 10 destinations.\n\na = flights |&gt;\n  filter(origin == \"JFK\") |&gt;\n  group_by(origin, dest) |&gt;\n  summarise(avg_delay = mean(dep_delay, na.rm = TRUE)) |&gt;\n  arrange(desc(avg_delay)) |&gt;\n  slice_head(n = 10) |&gt;\n  ungroup()\ngt(a) |&gt;\n  fmt_number(decimals = 2)\n\n\n\n\n\nTable 7:  The average departure delay from JFK airport to 10 destinations \n  \n\n    \n      origin\n      dest\n      avg_delay\n    \n  \n  \n    JFK\nCVG\n27.35\n    JFK\nSDF\n23.98\n    JFK\nEGE\n23.44\n    JFK\nSAT\n23.41\n    JFK\nMCI\n23.09\n    JFK\nCMH\n22.02\n    JFK\nORD\n21.55\n    JFK\nMSP\n21.33\n    JFK\nDEN\n20.10\n    JFK\nSTL\n20.00\n  \n\n\n\n\n\n\n\nNow, I use slice_min function with arguments n = 2 and then, with arguments n = -2 to show the difference in output. The first code n = 2 displays the two rows with minimum average delay. The second code, n = -2 displays the (total rows minus 2), i.e., 8 rows with minimum average delay.\n\n# n=2 displays the two rows with minimum average delay\na |&gt;\n  slice_min(n = 2, order_by = avg_delay)\n\n# A tibble: 2 × 3\n  origin dest  avg_delay\n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;\n1 JFK    STL        20  \n2 JFK    DEN        20.1\n\n# n=-2 displays the (total rows minus 2), i.e., 8 rows with minimum average delay\na |&gt;\n  slice_min(n = -2, order_by = avg_delay)\n\n# A tibble: 8 × 3\n  origin dest  avg_delay\n  &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;\n1 JFK    STL        20  \n2 JFK    DEN        20.1\n3 JFK    MSP        21.3\n4 JFK    ORD        21.6\n5 JFK    CMH        22.0\n6 JFK    MCI        23.1\n7 JFK    SAT        23.4\n8 JFK    EGE        23.4\n\n\nExplain what count() does in terms of the dplyr verbs you just learned. What does the sort argument to count() do?\nInstead of using the group_by() and summarize() verbs, the count() function can be used as a shortcut to quickly compute the number of unique values of each combination of a variable occurring in the data-set. Thus, count() helps us to calculate the number of values (rows) for each unique combination of variables which have been used as an argument in the count() function.\nThe inbuilt help in R tells us that df %&gt;% count(a, b) is roughly equivalent to df %&gt;% group_by(a, b) %&gt;% summarise(n = n()) .\nFurther, the sort = TRUE argument in count() tells R to display the largest groups (by count, i.e., n) to be displayed at the top.\nHere’s an example. The following code displays the 5 routes with maximum number of flights. For example, JFK to LAX had 11,262 flights in 2013. We can achieve this by using group_by(), summarize(), arrange() and ungroup(). Or, we can simply achieve the same result with a single function count().\n\nflights |&gt;\n  group_by(origin, dest) |&gt;\n  summarise(n = n()) |&gt;\n  arrange(desc(n)) |&gt;\n  ungroup() |&gt;\n  slice_head(n = 5)\n\n# A tibble: 5 × 3\n  origin dest      n\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n1 JFK    LAX   11262\n2 LGA    ATL   10263\n3 LGA    ORD    8857\n4 JFK    SFO    8204\n5 LGA    CLT    6168\n\nflights |&gt;\n  count(origin, dest, sort = TRUE) |&gt;\n  slice_head(n = 5)\n\n# A tibble: 5 × 3\n  origin dest      n\n  &lt;chr&gt;  &lt;chr&gt; &lt;int&gt;\n1 JFK    LAX   11262\n2 LGA    ATL   10263\n3 LGA    ORD    8857\n4 JFK    SFO    8204\n5 LGA    CLT    6168\n\n\nSuppose we have the following tiny data frame:\n\ndf &lt;- tibble(x = 1:5,   \n             y = c(\"a\", \"b\", \"a\", \"a\", \"b\"),   \n             z = c(\"K\", \"K\", \"L\", \"L\", \"K\") )\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what group_by() does.\ndf |&gt;   \n  group_by(y)\nIn my understanding, the output should look the same as df except that on top of it, a line mentioning that data is grouped by y should appear. When we run the code, it shows the following header # A tibble: 5 X 3 and #Groups: y[2] . Thus, there are two groups formed by two unique values of variable y , i.e., a and b .\n\ndf |&gt;\n  group_by(y)\n\n# A tibble: 5 × 3\n# Groups:   y [2]\n      x y     z    \n  &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 a     K    \n2     2 b     K    \n3     3 a     L    \n4     4 a     L    \n5     5 b     K    \n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what arrange() does. Also comment on how it’s different from the group_by() in part (a)?\ndf |&gt;   arrange(y)\nThe function arrange() re-orders the data-frame rows in ascending order of the variable mentioned, i.e. y . So, I expect the output to be the df tibble with ascending order of variable y . The ties will be arranged in the same order as they appeared in the original data-frame.\n\ndf |&gt;\n  arrange(y)\n\n# A tibble: 5 × 3\n      x y     z    \n  &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n1     1 a     K    \n2     3 a     L    \n3     4 a     L    \n4     2 b     K    \n5     5 b     K    \n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does.\ndf |&gt;   \n  group_by(y) |&gt;   \n  summarize(mean_x = mean(x))\nThe output should display the mean values of x for different values of y . For y = a , I expect mean_x = (1+3+4)/3 = 2.67 and for y = b , I expect mean_x = (2+5)/2 = 3.5 . I expect the output to be a 2 X 2 tibble with first column y and second column mean_x .\n\ndf |&gt;   \n  group_by(y) |&gt;   \n  summarize(mean_x = mean(x))\n\n# A tibble: 2 × 2\n  y     mean_x\n  &lt;chr&gt;  &lt;dbl&gt;\n1 a       2.67\n2 b       3.5 \n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does. Then, comment on what the message says.\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  summarize(mean_x = mean(x))\nNow, I expect R to form groups of various combinations of y and z , and then display average value of x for each combination. The output should be a tibble of 3 X 3, and still containing two groups of y .\n\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  summarize(mean_x = mean(x))\n\n# A tibble: 3 × 3\n# Groups:   y [2]\n  y     z     mean_x\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 a     K        1  \n2 a     L        3.5\n3 b     K        3.5\n\n\nWrite down what you think the output will look like, then check if you were correct, and describe what the pipeline does. How is the output different from the one in part (d).\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  summarize(mean_x = mean(x), .groups = \"drop\")\nI think the output will still be a 3 X 3 tibble with same values as answer from Question 6 (d), i.e. displaying average values of x for different combinations of y and z . But, now the remaining grouping, i.e., of y will be dropped from the output. So the output is visually the same, but now it is an un-grouped tibble, rather than the grouped tibble output of Question 6 (d).\n\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  summarize(mean_x = mean(x), .groups = \"drop\")\n\n# A tibble: 3 × 3\n  y     z     mean_x\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 a     K        1  \n2 a     L        3.5\n3 b     K        3.5\n\n\nWrite down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does. How are the outputs of the two pipelines different?\n# Code Chunk 1\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  summarize(mean_x = mean(x))  \n\n# Code Chunk 2\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  mutate(mean_x = mean(x))\nThe answers should be different because summarize() collapses all the rows for a unique combination of grouped variables to produce one summary row. On the other hand, mutate() preserves each row of the original data-frame (or, tibble) and produces and additional variable with mean of x to be entered in each row.\nThus, I expect the # Code Chunk 1 to generate a tibble of 3 X 3 (like the output in Question 6(d), while I expect the # Code Chunk 2 to generate a tibble of 5 X 4, with the 4th column of mean_x having different values for each unique combination of y and z .\nFurther, I expect that the # Code Chunk 1 will re-order the output in ascending of order grouping variables. But, the # Code Chunk 2 will preserve the original ordering of the rows as in the original df tibble.\n\n# Code Chunk 1\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  summarize(mean_x = mean(x))  \n\n# A tibble: 3 × 3\n# Groups:   y [2]\n  y     z     mean_x\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n1 a     K        1  \n2 a     L        3.5\n3 b     K        3.5\n\n# Code Chunk 2\ndf |&gt;   \n  group_by(y, z) |&gt;   \n  mutate(mean_x = mean(x))\n\n# A tibble: 5 × 4\n# Groups:   y, z [3]\n      x y     z     mean_x\n  &lt;int&gt; &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;\n1     1 a     K        1  \n2     2 b     K        3.5\n3     3 a     L        3.5\n4     4 a     L        3.5\n5     5 b     K        3.5\n\n\nNote: It is only by chance that the mean_x is 3.5 for both combinations:\n\ny=b, z=K , mean_x = (2+5)/2 = 3.5\ny=a, z=L , mean_x = (3+4)/2 = 3.5"
  },
  {
    "objectID": "Chapter3.html",
    "href": "Chapter3.html",
    "title": "Chapter 3",
    "section": "",
    "text": "Some important tips:\n\nUse Alt + - to write the assignment operator &lt;- in R.\nIn the comments, i.e, text written after # in code, explain the WHY of your code, not the WHAT or HOW.\n\n\n\n3.5 Exercises\n\nWhy does this code not work?\nmy_variable &lt;- 10 \nmy_varıable \n#&gt; Error in eval(expr, envir, enclos): object 'my_varıable' not found\nLook carefully! (This may seem like an exercise in pointlessness, but training your brain to notice even the tiniest difference will pay off when programming.)\nThe code does not work because of the minor spelling difference, i.e., i vs. ī .\nTweak each of the following R commands so that they run correctly:\nlibary(todyverse)  \nggplot(dTA = mpg) +    \n  geom_point(maping = aes(x = displ y = hwy)) +   \n  geom_smooth(method = \"lm)\nThe corrected code is as follows:---\n\nlibrary(tidyverse)  \nggplot(data = mpg, mapping = aes(x = displ, y = hwy)) +    \n  geom_point() +   \n  geom_smooth(method = \"lm\")\n\nPress Option + Shift + K / Alt + Shift + K. What happens? How can you get to the same place using the menus?\nThe Alt + Shift + K shortcut brings up the Keyboard Shortcut Quick Reference. We could get to the same using menus as Help –&gt; Keyboard Shortcuts Help.\nLet’s revisit an exercise from the Section 2.6. Run the following lines of code. Which of the two plots is saved as mpg-plot.png? Why?\nmy_bar_plot &lt;- ggplot(mpg, aes(x = class)) +   \n  geom_bar() \n\nmy_scatter_plot &lt;- ggplot(mpg, aes(x = cty, y = hwy)) +\n  geom_point() \n\nggsave(filename = \"mpg-plot.png\", plot = my_bar_plot)\nThis time, the bar plot, i.e. my_bar_plot is saved into the file mpg-plot.png because in the arguments to the function ggsave() we have specified the name of the plot. The plot argument tells ggsave() the Plot to save, and by default, it goes to the last plot displayed."
  },
  {
    "objectID": "Chapter5.html",
    "href": "Chapter5.html",
    "title": "Chapter 5",
    "section": "",
    "text": "5.6 Exercises\n\nRestyle the following pipelines following the guidelines above.\nflights|&gt;filter(dest==\"IAH\")|&gt;group_by(year,month,day)|&gt;summarize(n=n(),\ndelay=mean(arr_delay,na.rm=TRUE))|&gt;filter(n&gt;10)\n\nflights|&gt;filter(carrier==\"UA\",dest%in%c(\"IAH\",\"HOU\"),sched_dep_time&gt;\n0900,sched_arr_time&lt;2000)|&gt;group_by(flight)|&gt;summarize(delay=mean(\narr_delay,na.rm=TRUE),cancelled=sum(is.na(arr_delay)),n=n())|&gt;filter(n&gt;10)\nThe restyled code is as below:---\n\nlibrary(tidyverse)\nlibrary(nycflights13)\n\nflights |&gt;\n  filter(dest == \"IAH\") |&gt;\n  group_by(year, month, day) |&gt;\n  summarize(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  ) |&gt;\n  filter(n &gt; 10)\n\nflights |&gt;\n  filter(\n    carrier == \"UA\",\n    dest %in% c(\"IAH\", \"HOU\"),\n    sched_dep_time &gt; 0900,\n    sched_arr_time &lt; 2000\n  ) |&gt;\n  group_by(flight) |&gt;\n  summarize(\n    delay = mean(arr_delay, na.rm = TRUE),\n    cancelled = sum(is.na(arr_delay)), n = n()\n  ) |&gt;\n  filter(n &gt; 10)\n\nLet us try to use the styler package for the same task, using Ctrl + Shift + P . The styled code using styler is shown below:---\n\nflights |&gt;\n  filter(dest == \"IAH\") |&gt;\n  group_by(year, month, day) |&gt;\n  summarise(\n    n = n(),\n    delay = mean(arr_delay, na.rm = TRUE)\n  ) |&gt;\n  filter(n &gt; 10)\n\nflights |&gt;\n  filter(carrier == \"UA\", dest %in% c(\"IAH\", \"HOU\"), sched_dep_time &gt;\n    0900, sched_arr_time &lt; 2000) |&gt;\n  group_by(flight) |&gt;\n  summarise(delay = mean(\n    arr_delay,\n    na.rm = TRUE\n  ), cancelled = sum(is.na(arr_delay)), n = n()) |&gt;\n  filter(n &gt; 10)"
  },
  {
    "objectID": "Chapter6.html",
    "href": "Chapter6.html",
    "title": "Chapter 6",
    "section": "",
    "text": "6.2.1 Exercises\n\nQuestion 1\nFor each of the sample tables, describe what each observation and each column represents.\nFor table1 , the following columns represent:--\n\nCountry\nYear of the observation of cases and population\nNumber of cases\nTotal Population for that year\n\nFor table1 , each observation represents number of cases and total population for a country in a given year.\n\nFor table2 , the following columns represent:--\n\nCountry\nYear of the Observation\nWhich type of variable is represented in column 4 - i.e., cases or population. Thus, this column in itself is not a variable. Thus, this data-set is not tidy.\nThe actual value (i.e. observation) of the variable mentioned in Column 3.\n\nFor table2 , each observation represents either the number of cases or the total population for a country in a given year.\n\nFor table3 , the columns represent the following:--\n\nCountry\nYear of the observation\nThe ratio of two observations, i.e. rate = cases divided by the population. Thus, the column 3 represents two observations, not one. Hence, the data is not tidy.\n\nFor table3 , each observation is a rate, i.e., actually it is a ratio of two observations, namely, cases and population.\n\n\nQuestion 2\nSketch out the process you’d use to calculate the rate for table2 and table3. You will need to perform four operations:\n\na.\nExtract the number of TB cases per country per year.\nFor table2 , we will have to filter out rows where type == \"cases\" .\nFor table3 , we will have to extract the numerator from rate variable for each row.\n\n\nb.\nExtract the matching population per country per year.\nFor table2 , we will have to filter out rows where type == \"population\" .\nFor table3 , we will have to extract the denominator from rate variable for each row.\n\n\nc.\nDivide cases by population, and multiply by 10000.\nFor table2 , we will have to divide the observations from question 2 (a) by observations from question 2(b). We might also want to check that the year and country match, row by row.\nFor table3 , we can divide the numerator by denominator, and multiply by 10,000. Or simply calculate the expression in rate column, as a numeric.\n\n\nd.\nStore back in the appropriate place.\nFor table2 , we will have to re-save the rates in a new set of rows, where type == \"rate\" and count will be the calculated rate. Thus, the table2 will have 6 new rows.\nFor table3 , we will have to convert rate column into numeric, to get the ratio per 10,000. But we will end up losing information, i.e. the cases and population of each country for different years will be lost if data is reported directly as rate .\n\n\n\n\nSection 6.3.4\nData and variable names in the column headers\nHere’s an attempt to recreate \".values\" argument method in R :---\n\nlibrary(tidyverse)\nhousehold |&gt;\n  pivot_longer(\n    cols = !family,\n    names_to = c(\".value\", \"child\"),\n    names_sep = \"_\",\n    values_to = \"Value\",\n    values_drop_na = TRUE\n  )\n\n# A tibble: 9 × 4\n  family child  dob        name  \n   &lt;int&gt; &lt;chr&gt;  &lt;date&gt;     &lt;chr&gt; \n1      1 child1 1998-11-26 Susan \n2      1 child2 2000-01-29 Jose  \n3      2 child1 1996-06-22 Mark  \n4      3 child1 2002-07-11 Sam   \n5      3 child2 2004-04-05 Seth  \n6      4 child1 2004-10-10 Craig \n7      4 child2 2009-08-27 Khai  \n8      5 child1 2000-12-05 Parker\n9      5 child2 2005-02-28 Gracie\n\n\n\n\nSection 6.4.1\nHow does the pivot_wider() work?\nHere I try to understand what is the output from pivot_wider() is there are more than 1 unique values for a measurement, i.e.. there are two bp1 ’s for A .\n\ndf &lt;- tribble(\n  ~id, ~measurement, ~value,\n  \"A\",        \"bp1\",    100,\n  \"A\",        \"bp1\",    102,\n  \"A\",        \"bp2\",    120,\n  \"B\",        \"bp1\",    140, \n  \"B\",        \"bp2\",    115\n)\ndf |&gt;\n  pivot_wider(\n    id_cols = id,\n    names_from = measurement,\n    values_from = value\n  )\n## Warning: Values from `value` are not uniquely identified; output will contain list-cols.\n## • Use `values_fn = list` to suppress this warning.\n## • Use `values_fn = {summary_fun}` to summarise duplicates.\n## • Use the following dplyr code to identify duplicates.\n##   {data} %&gt;%\n##   dplyr::group_by(id, measurement) %&gt;%\n##   dplyr::summarise(n = dplyr::n(), .groups = \"drop\") %&gt;%\n##   dplyr::filter(n &gt; 1L)\n## # A tibble: 2 × 3\n##   id    bp1       bp2      \n##   &lt;chr&gt; &lt;list&gt;    &lt;list&gt;   \n## 1 A     &lt;dbl [2]&gt; &lt;dbl [1]&gt;\n## 2 B     &lt;dbl [1]&gt; &lt;dbl [1]&gt;\n\n# Using the Code given by R in Warning to find out the \n# duplicate observation\ndf |&gt;\n  group_by(id, measurement) |&gt;\n  summarise(n = n(), .groups = \"drop\") |&gt;\n  filter(n &gt; 1)\n## # A tibble: 1 × 3\n##   id    measurement     n\n##   &lt;chr&gt; &lt;chr&gt;       &lt;int&gt;\n## 1 A     bp1             2"
  },
  {
    "objectID": "Chapter7.html",
    "href": "Chapter7.html",
    "title": "Chapter 7",
    "section": "",
    "text": "7.3 Exercises\n\nQuestion 1\nGo to the RStudio Tips Twitter account, https://twitter.com/rstudiotips and find one tip that looks interesting. Practice using it!\nOne tip that I found interesting is the use of Ctrl + Shift + P to open the R-Studio Command Palette. I have embedded the tweet here by inserting a simple HTML block, and pasting the HTML code from public.twitter.com link.\nAccess it with Ctrl + Shift + P (Windows / Linux) or Cmd + Shift + P (macOS)!#rstats https://t.co/pWAYHGCWRr— RStudio Tips (@rstudiotips) October 26, 2022 \n\n\nQuestion 2\nWhat other common mistakes will RStudio diagnostics report? Read https://support.posit.co/hc/en-us/articles/205753617-Code-Diagnostics to find out.\nSome of the common mistakes that RStudio diagnostics will report are:--\n\nIt can detect if a variable named in a function has not yet been defined (i.e. the variable used has no definition in scope), or is misspelt.\nIt can detect if a variable has been defined, but is not being used within a function.\nIt can detect the missing punctuation, i.e. a missing comma or missing brackets.\nIt can detect whether the call within a function can work or not, i.e., whether the arguments to a function are matched, partially matched or unmatched.\nIt can detect if an essential argument to a function is missing.\nIt can provide us R code style diagnostics, e.g. white-space etc.\nIt can even detect mistakes in other languages such as C , C++ , JavaScript and Python ."
  },
  {
    "objectID": "Chapter8.html",
    "href": "Chapter8.html",
    "title": "Chapter 8",
    "section": "",
    "text": "8.2.4 Exercises\n\nlibrary(tidyverse)\nlibrary(gt)\n\n\nQuestion 1\nWhat function would you use to read a file where fields were separated with “|”?\nLet us first create a data set with “|” delimiter. I used ChatGPT to create a random data set and named it as the data to be imported, i.e., imp_df .\nI will use the function read_delim() to read a file where fields were separated with “|”, as shown below. The output is\n\n#| label: tbl-q1-Ex-8.2.4\n#| tbl-cap: \"Imported data using read_delim() function\"\n\nimport_df = \"Name|Age|Gender|City|Salary\nJohn|28|Male|New York|75000\nEmily|22|Female|Los Angeles|60000\nMichael|31|Male|Chicago|80000\nJessica|25|Female|Houston|65000\nWilliam|29|Male|Miami|70000\nSophia|27|Female|San Francisco|75000\nDaniel|24|Male|Seattle|72000\nOlivia|30|Female|Boston|78000\nJames|26|Male|Dallas|67000\nAva|23|Female|Atlanta|62000\"\n\ndf = read_delim(import_df, delim = \"|\")\n\ndf |&gt;\n  gt()\n\n\n\n\n\n  \n    \n    \n      Name\n      Age\n      Gender\n      City\n      Salary\n    \n  \n  \n    John\n28\nMale\nNew York\n75000\n    Emily\n22\nFemale\nLos Angeles\n60000\n    Michael\n31\nMale\nChicago\n80000\n    Jessica\n25\nFemale\nHouston\n65000\n    William\n29\nMale\nMiami\n70000\n    Sophia\n27\nFemale\nSan Francisco\n75000\n    Daniel\n24\nMale\nSeattle\n72000\n    Olivia\n30\nFemale\nBoston\n78000\n    James\n26\nMale\nDallas\n67000\n    Ava\n23\nFemale\nAtlanta\n62000\n  \n  \n  \n\n\n\n\nNote: The same read_delim() function will even work without the argument delim = \"|\" because it has in-built capacity to identify the delimiter.\n\n\nQuestion 2\nApart from file, skip, and comment, what other arguments do read_csv() and read_tsv() have in common?\nWhile read_csv() works for comma separated files, read_tsv() works for tab-separated files. The arguments for each of them are as follows:-\n\n\n\nArguments for read_csv\n\nfile,\ncol_names = TRUE,\ncol_types = NULL,\ncol_select = NULL,\nid = NULL,\nlocale = default_locale(),\nna = c(\"\", \"NA\"),\nquoted_na = TRUE,\nquote = \"\\\"\",\ncomment = \"\",\ntrim_ws = TRUE,\nskip = 0,\nn_max = Inf,\nguess_max = min(1000, n_max),\nname_repair = \"unique\",\nnum_threads = readr_threads(),\nprogress = show_progress(),\nshow_col_types = should_show_types(),\nskip_empty_rows = TRUE,\nlazy = should_read_lazy()\n\n\n\nArguments for read_tsv\n\nfile,\ncol_names = TRUE,\ncol_types = NULL,\ncol_select = NULL,\nid = NULL,\nlocale = default_locale(),\nna = c(\"\", \"NA\"),\nquoted_na = TRUE,\nquote = \"\\\"\",\ncomment = \"\",\ntrim_ws = TRUE,\nskip = 0,\nn_max = Inf,\nguess_max = min(1000, n_max),\nname_repair = \"unique\",\nnum_threads = readr_threads(),\nprogress = show_progress(),\nshow_col_types = should_show_types(),\nskip_empty_rows = TRUE,\nlazy = should_read_lazy()\n\n\n\n\nThus, all the arguments to both the functions are common, and have the exact same role.\n\n\nQuestion 3\nWhat are the most important arguments to read_fwf()?\nThe fixed width files are very fast to parse because each field will be in exact sample place in each line. However, this means, we must know the exact width of each column. Hence, the most important argument to read_fwf() is the cols_position = , which can take the following values:\n\nfwf_empty() - Guesses based on the positions of empty columns.\nfwf_widths() - Supply the widths of the columns.\nfwf_positions() - Supply paired vectors of start and end positions.\nfwf_cols() - Supply named arguments of paired start and end positions or column widths.\n\nAlso, another important argument is cols_types which will tell whether each column will be of which class - character, integer, factor etc.\nHere’s an example shown in Table 1 .\n\nimport_fwf_data = \"John    Smith   35  New York\nAlice   Johnson 28  Los Angeles\nMichael Williams 42  Chicago\"\n\ndf2 = read_fwf(\n  import_fwf_data,\n  col_positions = fwf_widths(c(8, 8, 3, 12))\n) \n\ncolnames(df2) = c(\"Name\", \"Surname\", \"Age\", \"City\")\n\ndf2 |&gt;\n  gt()\n\n\n\n\n\nTable 1:  Fixed Width File Data parsed using read_fwf \n  \n    \n    \n      Name\n      Surname\n      Age\n      City\n    \n  \n  \n    John\nSmith\n35\nNew York\n    Alice\nJohnson\n28\nLos Angeles\n    Michael\nWilliams\n42\nChicago\n  \n  \n  \n\n\n\n\n\n\n\nQuestion 4\nSometimes strings in a CSV file contain commas. To prevent them from causing problems, they need to be surrounded by a quoting character, like ” or ’. By default, read_csv() assumes that the quoting character will be “. To read the following text into a data frame, what argument to read_csv() do you need to specify?\n\"x,y\\n1,'a,b'\"\nTo read a data above text into a data-frame, we will need to used the argument quote = \"'\" . Here’s an example in Table 2 .\n\nimport_quote = \"x,y\\n1,'a,b'\"\n\nread_csv(\n  import_quote,\n  quote = \"'\",\n  col_names = FALSE\n) |&gt;\n  gt()\n\n\n\n\n\nTable 2:  A data-frame imported from csv file with different quotes \n  \n    \n    \n      X1\n      X2\n    \n  \n  \n    x\ny\n    1\na,b\n  \n  \n  \n\n\n\n\n\n\n\nQuestion 5\nIdentify what is wrong with each of the following inline CSV files. What happens when you run the code?\n\nread_csv(\"a,b\\n1,2,3\\n4,5,6\") : This data is not rectangular, there are only two columns in first row, but three in other two rows. Thus, R ends up reading only two columns by default and joins the second and third column values for the two observations.\n\nread_csv(\"a,b\\n1,2,3\\n4,5,6\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 2 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (1): a\nnum (1): b\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 2\n      a     b\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1    23\n2     4    56\n\n\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\"): This data is again not rectangular, there are three columns (column names) in first row, but two values in second row, and four in the third row. Thus, R ends up reading three columns by default, creates an NA and joins the second and third column values for the second row.\n\nread_csv(\"a,b,c\\n1,2\\n1,2,3,4\")\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 2 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (2): a, b\nnum (1): c\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 3\n      a     b     c\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2    NA\n2     1     2    34\n\n\nread_csv(\"a,b\\n\\\"1\"): This data is entered wrong, as the double quotes don’t match up in pairs, i.e., there are three double quotes (\"), so R will read only the data between first two, i.e, a and b as variable names, and the data-frame will be empty. An error with also be displayed, as shown below:---\n\nread_csv(\"a,b\\n\\\"1\")\n\nRows: 0 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): a, b\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 0 × 2\n# ℹ 2 variables: a &lt;chr&gt;, b &lt;chr&gt;\n\n\nread_csv(\"a,b\\n1,2\\na,b\"): This data is rectangular, but the names of the columns are repeated in the second row, i.e. the second observation. Further, the data in each column is not of a single type, i.e. either &lt;chr&gt; or &lt;dbl&gt; or &lt;int&gt; etc. Thus, each column is not a variable, and each row is not an observation. The data is not tidy.\n\nread_csv(\"a,b\\n1,2\\na,b\")\n\nRows: 2 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): a, b\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 2 × 2\n  a     b    \n  &lt;chr&gt; &lt;chr&gt;\n1 1     2    \n2 a     b    \n\n\nread_csv(\"a;b\\n1;3\"): This data is wrong coded, i.e. it is not a comma-separated data, rather it is a semi-colon-separated data. Thus, read_csv() will end up reading a;b as a single string (i.e., column name) and the 1;3 as the single observation, i.e. first row. Instead, we should have used read_csv2() here.\n\nread_csv(\"a;b\\n1;3\")\n\nRows: 1 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): a;b\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 1 × 1\n  `a;b`\n  &lt;chr&gt;\n1 1;3  \n\n\nUsing read_csv2() , the data is read-in correctly:---\n\nread_csv2(\"a;b\\n1;3\")\n\n# A tibble: 1 × 2\n      a     b\n  &lt;dbl&gt; &lt;dbl&gt;\n1     1     3\n\n\n\n\n\nQuestion 6\nPractice referring to non-syntactic names in the following data frame by:\n\nannoying &lt;- tibble(\n  `1` = 1:10,\n  `2` = `1` * 2 + rnorm(length(`1`))\n)\nannoying\n\n# A tibble: 10 × 2\n     `1`   `2`\n   &lt;int&gt; &lt;dbl&gt;\n 1     1  4.42\n 2     2  5.82\n 3     3  6.75\n 4     4  8.48\n 5     5 10.3 \n 6     6 12.9 \n 7     7 14.4 \n 8     8 16.7 \n 9     9 16.8 \n10    10 18.6 \n\n\n\nExtracting the variable called 1.\n\nannoying |&gt;\n  pull(`1`)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nPlotting a scatterplot of 1 vs. 2.\n\nannoying |&gt;\n  ggplot(aes(x = `1`, y = `2`)) +\n  geom_point() +\n  theme_classic()\n\n\n\n\nCreating a new column called 3, which is 2 divided by 1.\n\nannoying = annoying |&gt;\n  mutate(`3` = `2` / `1`)\nannoying\n\n# A tibble: 10 × 3\n     `1`   `2`   `3`\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1  4.42  4.42\n 2     2  5.82  2.91\n 3     3  6.75  2.25\n 4     4  8.48  2.12\n 5     5 10.3   2.05\n 6     6 12.9   2.14\n 7     7 14.4   2.06\n 8     8 16.7   2.09\n 9     9 16.8   1.86\n10    10 18.6   1.86\n\n\nRenaming the columns to one, two, and three.\n\nannoying |&gt;\n  rename(\n    \"one\" = `1`,\n    \"two\" = `2`,\n    \"three\" = `3`\n  )\n\n# A tibble: 10 × 3\n     one   two three\n   &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1  4.42  4.42\n 2     2  5.82  2.91\n 3     3  6.75  2.25\n 4     4  8.48  2.12\n 5     5 10.3   2.05\n 6     6 12.9   2.14\n 7     7 14.4   2.06\n 8     8 16.7   2.09\n 9     9 16.8   1.86\n10    10 18.6   1.86\n\n\n\n\n\n\n8.3 Controlling column types\nHere’s an example data set to use the arguments col_types and na associated with the powerful read_csv() function.\n\nraw_df1 = \"Name,Age,Value,DateTime,Flag\nJohn Doe,25,123.45,2023-08-07 10:30:00,True\nJane Smith,42,987.65,2023-08-06 15:45:00,False\nBob Johnson,32,543.21,2023-08-05 08:00:00,True\nMary Williams,28,.,2023-08-04 12:15:00,False\nMichael Brown,,789.01,2023-08-03 18:30:00,True\nEmily Davis,38,234.56,,False\nDavid Lee,50,.,2023-08-01 09:45:00,True\n.,22,345.67,2023-07-31 14:00:00,False\"\n\nread_csv(raw_df1)\n\n# A tibble: 8 × 5\n  Name            Age Value  DateTime            Flag \n  &lt;chr&gt;         &lt;dbl&gt; &lt;chr&gt;  &lt;dttm&gt;              &lt;lgl&gt;\n1 John Doe         25 123.45 2023-08-07 10:30:00 TRUE \n2 Jane Smith       42 987.65 2023-08-06 15:45:00 FALSE\n3 Bob Johnson      32 543.21 2023-08-05 08:00:00 TRUE \n4 Mary Williams    28 .      2023-08-04 12:15:00 FALSE\n5 Michael Brown    NA 789.01 2023-08-03 18:30:00 TRUE \n6 Emily Davis      38 234.56 NA                  FALSE\n7 David Lee        50 .      2023-08-01 09:45:00 TRUE \n8 .                22 345.67 2023-07-31 14:00:00 FALSE\n\n\nHere, we see that by default, read_csv() does an amazing job. It identifies most column types, but fails to understand that “.” is a missing value in Value variable, which is otherwise numerical.\nLet’s improve this behavior.\n\nread_csv(\n  raw_df1,\n  na = \".\"\n)\n\n# A tibble: 8 × 5\n  Name            Age Value DateTime            Flag \n  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt;              &lt;lgl&gt;\n1 John Doe         25  123. 2023-08-07 10:30:00 TRUE \n2 Jane Smith       42  988. 2023-08-06 15:45:00 FALSE\n3 Bob Johnson      32  543. 2023-08-05 08:00:00 TRUE \n4 Mary Williams    28   NA  2023-08-04 12:15:00 FALSE\n5 Michael Brown    NA  789. 2023-08-03 18:30:00 TRUE \n6 Emily Davis      38  235. NA                  FALSE\n7 David Lee        50   NA  2023-08-01 09:45:00 TRUE \n8 &lt;NA&gt;             22  346. 2023-07-31 14:00:00 FALSE\n\n\nNow, let’s use col_types argument to force some variables into certain classes we desire. Here I will try to force Age into an integer, Value into a number (i.e., &lt;dbl&gt;), and DateTime into a character, and Flag into a character.\n\nread_csv(\n  raw_df1,\n  na = \".\",\n  col_types = list(\n    Name = col_character(),\n    Age = col_integer(),\n    Value = col_double(),\n    DateTime = col_character()\n  )\n)\n\n# A tibble: 8 × 5\n  Name            Age Value DateTime              Flag \n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;lgl&gt;\n1 John Doe         25  123. \"2023-08-07 10:30:00\" TRUE \n2 Jane Smith       42  988. \"2023-08-06 15:45:00\" FALSE\n3 Bob Johnson      32  543. \"2023-08-05 08:00:00\" TRUE \n4 Mary Williams    28   NA  \"2023-08-04 12:15:00\" FALSE\n5 Michael Brown    NA  789. \"2023-08-03 18:30:00\" TRUE \n6 Emily Davis      38  235. \"\"                    FALSE\n7 David Lee        50   NA  \"2023-08-01 09:45:00\" TRUE \n8 &lt;NA&gt;             22  346. \"2023-07-31 14:00:00\" FALSE\n\n\nNow, I will try to read-in only a few columns to save on memory space in R by using col_skip().\n\nread_csv(\n  raw_df1,\n  na = \".\",\n  col_types = list(\n    Name = col_character(),\n    Age = col_integer(),\n    Value = col_double(),\n    DateTime = col_skip(),\n    Flag = col_skip()\n  )\n)\n\n# A tibble: 8 × 3\n  Name            Age Value\n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1 John Doe         25  123.\n2 Jane Smith       42  988.\n3 Bob Johnson      32  543.\n4 Mary Williams    28   NA \n5 Michael Brown    NA  789.\n6 Emily Davis      38  235.\n7 David Lee        50   NA \n8 &lt;NA&gt;             22  346.\n\n\nNow, I will repeat this using cols_only() function:---\n\nread_csv(\n  raw_df1,\n  na = \".\",\n  col_types = cols_only(\n    Name = col_character(), \n    Age = col_integer(), \n    Value = col_double())\n)\n\n# A tibble: 8 × 3\n  Name            Age Value\n  &lt;chr&gt;         &lt;int&gt; &lt;dbl&gt;\n1 John Doe         25  123.\n2 Jane Smith       42  988.\n3 Bob Johnson      32  543.\n4 Mary Williams    28   NA \n5 Michael Brown    NA  789.\n6 Emily Davis      38  235.\n7 David Lee        50   NA \n8 &lt;NA&gt;             22  346.\n\n\nNow, let’s try to read-in data from three different files at the same time..\n\nread_csv(\n  c(\n    \"https://pos.it/r4ds-01-sales\", \n    \"https://pos.it/r4ds-02-sales\", \n    \"https://pos.it/r4ds-03-sales\"\n  ),\n  na = \".\",\n  id = \"file\"\n) |&gt;\n  slice_head(n = 5)\n\n# A tibble: 5 × 6\n  file                         month    year brand  item     n\n  &lt;chr&gt;                        &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 https://pos.it/r4ds-01-sales January  2019     1  1234     3\n2 https://pos.it/r4ds-01-sales January  2019     1  8721     9\n3 https://pos.it/r4ds-01-sales January  2019     1  1822     2\n4 https://pos.it/r4ds-01-sales January  2019     2  3333     1\n5 https://pos.it/r4ds-01-sales January  2019     2  2156     9"
  },
  {
    "objectID": "Chapter9.html#making-a-reprex",
    "href": "Chapter9.html#making-a-reprex",
    "title": "Chapter 9",
    "section": "9.2 Making a reprex",
    "text": "9.2 Making a reprex\nHere, I try to create a reprex for a deliberate mistake I am making in ggplot2 :--\nFirst, I create the faulty ggplot2 code:--\n\nlibrary(tidyverse)\nlibrary(ggrepel)\nlibrary(gt)\ndata(\"gtcars\")\ngtcars |&gt;\n  slice_head(n = 3, \n             by = ctry_origin) |&gt;\n  ggplot(aes(x = hp,\n             y = mpg_h,\n             color = ctry_origin,\n             label = model)) +\n  geom_point() +\n  geom_text_repel(force = 2) +\n  theme_classic() +\n  labs(x = \"Horse Power\",\n       y = \"Miles per Gallon (Highway)\") +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())\n\n\n# Copy the code above\n\n# Then create reprex data set\ngtcars |&gt;\n  slice_head(n = 3, \n             by = ctry_origin) |&gt;\n  dput()\n\nHere’s the reprex:\n\ngtcars = \nstructure(list(mfr = c(\"Ford\", \"Chevrolet\", \"Dodge\", \"Ferrari\", \n\"Ferrari\", \"Ferrari\", \"Acura\", \"Nissan\", \"Bentley\", \"Aston Martin\", \n\"Aston Martin\", \"BMW\", \"BMW\", \"BMW\"), model = c(\"GT\", \"Corvette\", \n\"Viper\", \"458 Speciale\", \"458 Spider\", \"458 Italia\", \"NSX\", \"GT-R\", \n\"Continental GT\", \"DB11\", \"Rapide S\", \"6-Series\", \"i8\", \"M4\"), \n    year = c(2017, 2016, 2017, 2015, 2015, 2014, 2017, 2016, \n    2016, 2017, 2016, 2016, 2016, 2016), trim = c(\"Base Coupe\", \n    \"Z06 Coupe\", \"GT Coupe\", \"Base Coupe\", \"Base\", \"Base Coupe\", \n    \"Base Coupe\", \"Premium Coupe\", \"V8 Coupe\", \"Base Coupe\", \n    \"Base Sedan\", \"640 I Coupe\", \"Mega World Coupe\", \"Base Coupe\"\n    ), bdy_style = c(\"coupe\", \"coupe\", \"coupe\", \"coupe\", \"convertible\", \n    \"coupe\", \"coupe\", \"coupe\", \"coupe\", \"coupe\", \"sedan\", \"coupe\", \n    \"coupe\", \"coupe\"), hp = c(647, 650, 645, 597, 562, 562, 573, \n    545, 500, 608, 552, 315, 357, 425), hp_rpm = c(6250, 6400, \n    5000, 9000, 9000, 9000, 6500, 6400, 6000, 6500, 6650, 5800, \n    5800, 5500), trq = c(550, 650, 600, 398, 398, 398, 476, 436, \n    487, 516, 465, 330, 420, 406), trq_rpm = c(5900, 3600, 5000, \n    6000, 6000, 6000, 2000, 3200, 1700, 1500, 5500, 1400, 3700, \n    1850), mpg_c = c(11, 15, 12, 13, 13, 13, 21, 16, 15, 15, \n    14, 20, 28, 17), mpg_h = c(18, 22, 19, 17, 17, 17, 22, 22, \n    25, 21, 21, 30, 29, 24), drivetrain = c(\"rwd\", \"rwd\", \"rwd\", \n    \"rwd\", \"rwd\", \"rwd\", \"awd\", \"awd\", \"awd\", \"rwd\", \"rwd\", \"rwd\", \n    \"awd\", \"rwd\"), trsmn = c(\"7a\", \"7m\", \"6m\", \"7a\", \"7a\", \"7a\", \n    \"9a\", \"6a\", \"8am\", \"8am\", \"8am\", \"8am\", \"6am\", \"6m\"), ctry_origin = c(\"United States\", \n    \"United States\", \"United States\", \"Italy\", \"Italy\", \"Italy\", \n    \"Japan\", \"Japan\", \"United Kingdom\", \"United Kingdom\", \"United Kingdom\", \n    \"Germany\", \"Germany\", \"Germany\"), msrp = c(447000, 88345, \n    95895, 291744, 263553, 233509, 156000, 101770, 198500, 211195, \n    205300, 77300, 140700, 65700)), class = c(\"spec_tbl_df\", \n\"tbl_df\", \"tbl\", \"data.frame\"), row.names = c(NA, -14L), spec = structure(list(\n    cols = list(mfr = structure(list(), class = c(\"collector_character\", \n    \"collector\")), model = structure(list(), class = c(\"collector_character\", \n    \"collector\")), year = structure(list(), class = c(\"collector_double\", \n    \"collector\")), trim = structure(list(), class = c(\"collector_character\", \n    \"collector\")), bdy_style = structure(list(), class = c(\"collector_character\", \n    \"collector\")), hp = structure(list(), class = c(\"collector_double\", \n    \"collector\")), hp_rpm = structure(list(), class = c(\"collector_double\", \n    \"collector\")), trq = structure(list(), class = c(\"collector_double\", \n    \"collector\")), trq_rpm = structure(list(), class = c(\"collector_double\", \n    \"collector\")), mpg_c = structure(list(), class = c(\"collector_double\", \n    \"collector\")), mpg_h = structure(list(), class = c(\"collector_double\", \n    \"collector\")), drivetrain = structure(list(), class = c(\"collector_character\", \n    \"collector\")), trsmn = structure(list(), class = c(\"collector_character\", \n    \"collector\")), ctry_origin = structure(list(), class = c(\"collector_character\", \n    \"collector\")), msrp = structure(list(), class = c(\"collector_double\", \n    \"collector\"))), default = structure(list(), class = c(\"collector_guess\", \n    \"collector\")), skip = 1), class = \"col_spec\"))\n\nreprex::reprex()\n\n``` r\nlibrary(tidyverse)\nlibrary(ggrepel)\n\ngtcars |&gt;\n  slice_head(n = 3, \n             by = ctry_origin) |&gt;\n  ggplot(aes(x = hp,\n             y = mpg_h,\n             color = ctry_origin,\n             label = model)) +\n  geom_point() +\n  geom_text_repel(force = 2) +\n  theme_classic() +\n  labs(x = \"Horse Power\",\n       y = \"Miles per Gallon (Highway)\") +\n  theme(legend.position = \"bottom\",\n        legend.title = element_blank())\n\n```\n\n&lt;sup&gt;Created on 2023-08-13 with [reprex v2.0.2](https://reprex.tidyverse.org)&lt;/sup&gt;"
  },
  {
    "objectID": "Chapter21.html",
    "href": "Chapter21.html",
    "title": "Chapter 21",
    "section": "",
    "text": "21.2.9 Exercises\nThe two main packages for reading data from and writing data to excel spreadsheets are readxl and writexl . But they are not core-tidyverse, so let us load them first.\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(writexl)\n\nThe few important functions we will use are:\n\nread_excel()\nexcel_sheets()\n\n\nQuestion 1.\nIn an Excel file, create the following dataset and save it as survey.xlsx. Alternatively, you can download it as an Excel file from here. Then, read it into R, with survey_id as a character variable and n_pets as a numerical variable.\n\nsurvey_df = tibble(\n  survey_id = c(1:6),\n  n_pets = c(0,1,\"N/A\", \"two\", 2, \"\")\n)\n\nsurvey_df |&gt;\n  write_xlsx(\"docs/survey.xlsx\")\n\ndf = read_excel(\n  path = \"docs/survey.xlsx\",\n  col_names = TRUE,\n  col_types = c(\"text\", \"text\"),\n  na = c(\"N/A\", \"\")\n  ) |&gt;\n  mutate(\n    n_pets = ifelse(n_pets == \"two\", 2, n_pets),\n    n_pets = parse_number(n_pets)\n    )\n\ndf\n\n# A tibble: 6 × 2\n  survey_id n_pets\n  &lt;chr&gt;      &lt;dbl&gt;\n1 1              0\n2 2              1\n3 3             NA\n4 4              2\n5 5              2\n6 6             NA\n\n\n\n\nQuestion 2.\nIn another Excel file, create the following data-set and save it as roster.xlsx. Alternatively, you can download it as an Excel file from here. Then, read it into R. The resulting data frame should be called roster and should look like the following.\nThere are two ways of doing this:\n\nUsing the read_excel() function with fill() function of the tidyr package.\nUsing the package openxlsx and its function read.xlsx() which has an argument fillMergedCells = TRUE to do the same task in one go. However, the output is a data.frame, which we must then convert to a tibble.\n\n\n# Use readxl package with fill() from tidyr\nread_excel(\n  path = \"docs/roster.xlsx\"\n  ) |&gt;\n  fill(group, subgroup)\n\n# A tibble: 12 × 3\n   group subgroup    id\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     1 A            1\n 2     1 A            2\n 3     1 A            3\n 4     1 B            4\n 5     1 B            5\n 6     1 B            6\n 7     1 B            7\n 8     2 A            8\n 9     2 A            9\n10     2 B           10\n11     2 B           11\n12     2 B           12\n\n# Option 2: using the openxlsx package\nlibrary(openxlsx)\nread.xlsx(\n  xlsxFile = \"docs/roster.xlsx\",\n  fillMergedCells = TRUE\n  ) |&gt;\n  as_tibble()\n\n# A tibble: 12 × 3\n   group subgroup    id\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     1 A            1\n 2     1 A            2\n 3     1 A            3\n 4     1 B            4\n 5     1 B            5\n 6     1 B            6\n 7     1 B            7\n 8     2 A            8\n 9     2 A            9\n10     2 B           10\n11     2 B           11\n12     2 B           12\n\n\n\n\nQuestion 3.\nIn a new Excel file, create the following dataset and save it as sales.xlsx. Alternatively, you can download it as an Excel file from here.\n\nRead sales.xlsx in and save as sales. The data frame should look like the following, with id and n as column names and with 9 rows.\n\nsales = read_excel(\n  \"docs/sales.xlsx\",\n  skip = 4,\n  col_names = c(\"id\", \"n\")\n)\nsales\n\n# A tibble: 9 × 2\n  id      n    \n  &lt;chr&gt;   &lt;chr&gt;\n1 Brand 1 n    \n2 1234.0  8.0  \n3 8721.0  2.0  \n4 1822.0  3.0  \n5 Brand 2 n    \n6 3333.0  1.0  \n7 2156.0  3.0  \n8 3987.0  6.0  \n9 3216.0  5.0  \n\n\nModify sales further to get it into the following tidy format with three columns (brand, id, and n) and 7 rows of data. Note that id and n are numeric, brand is a character variable.\n\nsales |&gt;\n  mutate(\n    brand = ifelse(str_detect(id, \"Brand\"), id, NA),\n    id = parse_number(id),\n    n = parse_number(n, na = \"n\")) |&gt;\n  fill(brand) |&gt;\n  drop_na() |&gt;\n  relocate(brand)\n\n# A tibble: 7 × 3\n  brand      id     n\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 Brand 1  1234     8\n2 Brand 1  8721     2\n3 Brand 1  1822     3\n4 Brand 2  3333     1\n5 Brand 2  2156     3\n6 Brand 2  3987     6\n7 Brand 2  3216     5\n\n\n\n\n\nQuestion 4.\nRecreate the bake_sale data frame, write it out to an Excel file using the write.xlsx() function from the openxlsx package.\n\nbake_sale = tibble(\n  item = factor(c(\"brownie\", \"cupcake\", \"cookie\")),\n  quantity = c(10, 5, 8)\n)\nbake_sale |&gt;\n  write.xlsx(\"docs/bake_sale.xlsx\")\n\n\n\nQuestion 5.\nIn Chapter 8 you learned about the janitor::clean_names() function to turn columns names into snake case. Read the students.xlsx file that we introduced earlier in this section and use this function to “clean” the column names.\n\n# Option 1: Read in data from the google sheets\n# library(googlesheets4)\n# id = \"1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w\"\n\n# For an easy reprex, write in the data now, suing:--\n# read_sheet(id) |&gt;\n#   dput()\n\nraw_data = structure(list(`Student ID` = c(1, 2, 3, 4, 5, 6), `Full Name` = c(\"Sunil Huffmann\", \"Barclay Lynn\", \"Jayendra Lyne\", \"Leon Rossini\", \"Chidiegwu Dunkel\",\"Güvenç Attila\"), favourite.food = c(\"Strawberry yoghurt\", \"French fries\", \"N/A\", \"Anchovies\", \"Pizza\", \"Ice cream\"), mealPlan = c(\"Lunch only\", \"Lunch only\", \"Breakfast and lunch\", \"Lunch only\", \"Breakfast and lunch\", \"Lunch only\"), AGE = list(4, 5, 7, NULL, \"five\", 6)), class = c(\"tbl_df\", \"tbl\", \"data.frame\"), row.names = c(NA, -6L))\n\nraw_data |&gt;\n  janitor::clean_names() |&gt;\n  as_tibble()\n\n# A tibble: 6 × 5\n  student_id full_name        favourite_food     meal_plan           age      \n       &lt;dbl&gt; &lt;chr&gt;            &lt;chr&gt;              &lt;chr&gt;               &lt;list&gt;   \n1          1 Sunil Huffmann   Strawberry yoghurt Lunch only          &lt;dbl [1]&gt;\n2          2 Barclay Lynn     French fries       Lunch only          &lt;dbl [1]&gt;\n3          3 Jayendra Lyne    N/A                Breakfast and lunch &lt;dbl [1]&gt;\n4          4 Leon Rossini     Anchovies          Lunch only          &lt;NULL&gt;   \n5          5 Chidiegwu Dunkel Pizza              Breakfast and lunch &lt;chr [1]&gt;\n6          6 Güvenç Attila    Ice cream          Lunch only          &lt;dbl [1]&gt;\n\n\n\n\nQuestion 6.\nWhat happens if you try to read in a file with .xlsx extension with read_xls()?\nIf we try to open a *.xlsx file with read_xls() , an error is displayed that Error: filepath libxls error: Unable to open file\n\nread_xls(\"docs/sales.xlsx\")\n\n\n\n\n21.3.6 Exercises\n\nQuestion 1.\nRead the students data set from earlier in the chapter from Excel and also from Google Sheets, with no additional arguments supplied to the read_excel() and read_sheet() functions. Are the resulting data frames in R exactly the same? If not, how are they different?\nThe two resulting data frames are not exactly the same. The data frame created from read_excel() , i.e. df_xl has the has variable AGE saved as character because one of the values is written in characters, instead of a number. Whenever some data is numeric and some data is character , read_excel() converts all data within a column into character format.\nOn the other hand, the data frame created from read_sheet() of googlesheets4 package, i.e. df_gs has this variable stored as a “list”, which contains both numeric and character types of data.\n\ndf_xl = read_excel(\"docs/students.xlsx\")\n\nlibrary(googlesheets4)\nurl_id = \"1V1nPp1tzOuutXFLb3G9Eyxi3qxeEhnOXUzL5_BcCQ0w\"\n\ndf_gs = read_sheet(url_id)\n# Comparing the types of columns in the two data.frames\nsapply(df_xl, class) == sapply(df_gs, class)\n\n    Student ID      Full Name favourite.food       mealPlan            AGE \n          TRUE           TRUE           TRUE           TRUE          FALSE \n\nclass(df_xl$AGE)\n\n[1] \"character\"\n\nclass(df_gs$AGE)\n\n[1] \"list\"\n\nsapply(df_gs$AGE, class)\n\n[1] \"numeric\"   \"numeric\"   \"numeric\"   \"NULL\"      \"character\" \"numeric\"  \n\n\n\n\nQuestion 2.\nRead the Google Sheet titled survey from https://pos.it/r4ds-survey, with survey_id as a character variable and n_pets as a numerical variable.\nWhen we read Google sheets, using col_types argument, we introduce NAs by coercion.\n\nurl_gs = \"https://docs.google.com/spreadsheets/d/1yc5gL-a2OOBr8M7B3IsDNX5uR17vBHOyWZq6xSTG2G8/edit#gid=0\"\n\nread_sheet(\n  ss = url_gs,\n  col_types = \"cd\")\n\n# A tibble: 6 × 2\n  survey_id n_pets\n  &lt;chr&gt;      &lt;dbl&gt;\n1 1              0\n2 2              1\n3 3             NA\n4 4             NA\n5 5              2\n6 6             NA\n\n\n\n\nQuestion 3.\nRead the Google Sheet titled roster from https://pos.it/r4ds-roster. The resulting data frame should be called roster and should look like the following.\n\nurl_gs1 = \"https://docs.google.com/spreadsheets/d/1LgZ0Bkg9d_NK8uTdP2uHXm07kAlwx8-Ictf8NocebIE/edit#gid=0\"\n\nread_sheet(\n  ss = url_gs1\n) |&gt;\nfill(group, subgroup)  \n\n# A tibble: 12 × 3\n   group subgroup    id\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     1 A            1\n 2     1 A            2\n 3     1 A            3\n 4     1 B            4\n 5     1 B            5\n 6     1 B            6\n 7     1 B            7\n 8     2 A            8\n 9     2 A            9\n10     2 B           10\n11     2 B           11\n12     2 B           12"
  },
  {
    "objectID": "Chapter9.html",
    "href": "Chapter9.html",
    "title": "Chapter 9",
    "section": "",
    "text": "We can copy any error; paste and search it on google.com"
  },
  {
    "objectID": "Chapter9.html#google-is-your-friend",
    "href": "Chapter9.html#google-is-your-friend",
    "title": "Chapter 9",
    "section": "",
    "text": "We can copy any error; paste and search it on google.com"
  },
  {
    "objectID": "Chapter10.html",
    "href": "Chapter10.html",
    "title": "Chapter 10",
    "section": "",
    "text": "“The greatest value of a picture is when it forces us to notice what we never expected to see.” — John Tukey\n\n\nggplot2 will use maximum 6 shapes at a time. The 7th shape is treated as a missing value.\nUsing alpha aesthetic for a discrete variable is not advised.\nThe shapes used in ggplot2 are as follows(Wickham 2016) :--\n\n\n\nShapes available to use in ggplot2.\n\n\nThe best place to explore ggplot2 extensions and graphs is the ggplot2 extensions gallery.\nBest place to search for and understand the geoms within ggplot2 is ggplot2 Function Reference.\n\n\nlibrary(tidyverse)\nlibrary(gt)\ndata(\"mpg\")\ndata(\"diamonds\")"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\nHarvard University | Boston, MA MPH in Global Health | Aug 2021 - May 2022\nAll India Institute of Medical Sciences | New Delhi, India MBBS in Medicine | Aug 2005-Dec 2010\nIndira Gandhi National Open University | New Delhi, India MA in Public Policy | Jan 2012 - Dec 2013"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nIndian Administrative Service | Director | Aug 2011 - present\nNeuro-Radiology, AIIMS New Delhi | Junior Resident Doctor | Jan 2011 - Aug 2011"
  },
  {
    "objectID": "Chapter10.html#footnotes",
    "href": "Chapter10.html#footnotes",
    "title": "Chapter 10",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWritten with help from ChatGPT 3.5. OpenAI. (2023). ChatGPT (Aug 22, 2023 version) [Large language model]. https://chat.openai.com↩︎\nThis portion of answer was created using help from ChatGPT 3.5. OpenAI. (2023). ChatGPT (Aug 22, 2023 version) [Large language model]. https://chat.openai.com↩︎\nggplot2, Map projections. https://ggplot2.tidyverse.org/reference/coord_map.html↩︎"
  }
]